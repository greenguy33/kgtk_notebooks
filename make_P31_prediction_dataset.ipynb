{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de048b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from kgtk.configure_kgtk_notebooks import ConfigureKGTK\n",
    "from kgtk.functions import kgtk, kypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "property_id = \"P39\"\n",
    "\n",
    "# make shuffled verison of claims\n",
    "if not os.path.isfile(f'/out/data/propertiesSplit_final/claims.{property_id}.shuffled.tsv'):\n",
    "    all_lines = []\n",
    "    tsv_file = open(f'/out/data/propertiesSplit_final/claims.{property_id}.tsv')\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    next(read_tsv)\n",
    "    for line in read_tsv:\n",
    "        all_lines.append(line)\n",
    "    random.shuffle(all_lines)\n",
    "    with open(f'/out/data/propertiesSplit_final/claims.{property_id}.shuffled.tsv', 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerows(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d01651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make link prediction dataset for P31\n",
    "# assumes existence of separate file with all P31 relationships for the subjects and objects connected with this property\n",
    "# this runs a kypher query for each Q node and is not efficient. Could be improved with batching.\n",
    "# takes about 7 hours per property currently.\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def queryKgtk(node, writer):\n",
    "    try:\n",
    "        # get triples with node as subject\n",
    "        res = kgtk(f\"\"\"query\n",
    "        -i /out/labels.en.tsv.gz --as labels\n",
    "        -i /out/claims.wikibase-item.tsv.gz --as claims\n",
    "        --match 'claims: (:{node})-[someProp]->(node2)'\n",
    "        --opt 'labels: (:{node})-[:label]->(lbSubj)'\n",
    "        --opt 'labels: (node2)-[:label]->(lbObj)'\n",
    "        --return 'distinct node2 as `object`, someProp as `prop`, lbSubj as `subjectLabel`, lbObj as `objectLabel`'\n",
    "        \"\"\")\n",
    "        tempRes = []\n",
    "        addToMain = False\n",
    "        # only add if node has P31 relationship\n",
    "        for ind, elem in enumerate(res.object):\n",
    "            if res.prop[ind].split(\"-\")[1] == \"P31\":\n",
    "                addToMain = True\n",
    "            else:\n",
    "                tempRes.append([node, res.subjectLabel[ind], res.prop[ind].split(\"-\")[1], res.object[ind], res.objectLabel[ind], \"subject\"])\n",
    "        if addToMain:\n",
    "            for row in tempRes:\n",
    "                writer.writerow(row)\n",
    "            # get triples with node as object (only execute if addToMain == True)\n",
    "            res = kgtk(f\"\"\"query\n",
    "            -i /out/labels.en.tsv.gz --as labels\n",
    "            -i /out/claims.wikibase-item.tsv.gz --as claims\n",
    "            --match 'claims: (node2)-[someProp]->(:{node})'\n",
    "            --opt 'labels: (:{node})-[:label]->(lbObj)'\n",
    "            --opt 'labels: (node2)-[:label]->(lbSubj)'\n",
    "            --return 'distinct node2 as `subject`, someProp as `prop`, lbSubj as `subjectLabel`, lbObj as `objectLabel`'\n",
    "            \"\"\")\n",
    "            tempRes = []\n",
    "            addToMain = False\n",
    "            for ind, elem in enumerate(res.subject):\n",
    "                tempRes.append([node, res.objectLabel[ind], res.prop[ind].split(\"-\")[1], res.subject[ind], res.subjectLabel[ind], \"object\"])\n",
    "            for row in tempRes:\n",
    "                writer.writerow(row)\n",
    "                    \n",
    "    except AttributeError:\n",
    "        print(\"Caught Attribute Error; trying again\")\n",
    "        queryKgtk(node, writer)\n",
    "\n",
    "tsv_file = open(f\"/out/data/propertiesSplit_final/claims.{property_id}.shuffled.tsv\")\n",
    "input_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "count = 0\n",
    "datasetSize = 2500\n",
    "\n",
    "dis_subj_classes = set()\n",
    "dis_obj_classes = set()\n",
    "\n",
    "# load pre-computed classes\n",
    "if os.path.isfile(f'/out/output/instance_prediction_datasets/{property_id}.subjects.tsv'):\n",
    "    tsv_file = open(f'/out/output/instance_prediction_datasets/{property_id}.subjects.tsv')\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    next(read_tsv)\n",
    "    for line in read_tsv:\n",
    "        dis_subj_classes.add(line[0])\n",
    "if os.path.isfile(f'/out/output/instance_prediction_datasets/{property_id}.objects.tsv'):\n",
    "    tsv_file = open(f'/out/output/instance_prediction_datasets/{property_id}.objects.tsv')\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    next(read_tsv)\n",
    "    for line in read_tsv:\n",
    "        dis_obj_classes.add(line[0])\n",
    "        \n",
    "print(dis_subj_classes)\n",
    "print(dis_obj_classes)\n",
    "        \n",
    "if os.path.isfile(f'/out/output/instance_prediction_datasets/{property_id}.subjects.tsv'):\n",
    "    writemode = 'a'\n",
    "else:\n",
    "    writemode = 'x'\n",
    "with open(f'/out/output/instance_prediction_datasets/{property_id}.subjects.tsv', writemode) as subj_file, open(f'/out/output/instance_prediction_datasets/{property_id}.objects.tsv', writemode) as obj_file:\n",
    "    subj_writer = csv.writer(subj_file, delimiter='\\t')\n",
    "    obj_writer = csv.writer(obj_file, delimiter='\\t')\n",
    "    if writemode == 'x':\n",
    "        subj_writer.writerow(['node','nodeLabel','prop','nodeConnection','connectionLabel','nodeOrientation'])\n",
    "        obj_writer.writerow(['node','nodeLabel','prop','nodeConnection','connectionLabel','nodeOrientation'])\n",
    "    for line in input_tsv:\n",
    "        if line[0].startswith(\"Q\") and line[2].startswith(\"Q\"):\n",
    "            subj = line[0]\n",
    "            obj = line[2]\n",
    "\n",
    "            if subj not in dis_subj_classes:\n",
    "                dis_subj_classes.add(subj)\n",
    "                if len(dis_subj_classes) <= datasetSize:\n",
    "                    queryKgtk(subj, subj_writer)\n",
    "            print(\"Subject classes completed: \", len(dis_subj_classes))\n",
    "            \n",
    "            if obj not in dis_obj_classes:\n",
    "                dis_obj_classes.add(obj)\n",
    "                if len(dis_obj_classes) <= datasetSize:\n",
    "                    queryKgtk(obj, obj_writer)\n",
    "            print(\"Object classes completed: \", len(dis_obj_classes))\n",
    "\n",
    "            if len(dis_subj_classes) >= datasetSize and len(dis_obj_classes) >= datasetSize:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
