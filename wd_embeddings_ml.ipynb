{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "property_label = \"P161\"\n",
    "orientation = \"subjects\"\n",
    "limit = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load instance dataset\n",
    "instances = {}\n",
    "tsv_file = open(f'../output/allConstraintsAnalysis_Final/instances/instances.{orientation}.{property_label}.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "for line in read_tsv:\n",
    "    if line[0] not in instances:\n",
    "        instances[line[0]] = [line[1]]\n",
    "    else:\n",
    "        instances[line[0]].append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 classes from data\n",
    "all_classes = set()\n",
    "instance_count = {}\n",
    "with open(f\"../output/instance_prediction_datasets/{property_label}.{orientation}.1250.tsv\",encoding=\"utf-8\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "    next(tsv_file)\n",
    "    for line in tsv_file:\n",
    "        all_classes.add(line[0])\n",
    "for qnode in all_classes:\n",
    "    instance_list = instances[qnode]\n",
    "    for this_instance in instance_list:\n",
    "        if this_instance in instance_count:\n",
    "            instance_count[this_instance]+=1\n",
    "        else:\n",
    "            instance_count[this_instance]=1\n",
    "print({k: v for k, v in sorted(instance_count.items(), key=lambda item: item[1], reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset for top 10 classes\n",
    "classes_to_use = set()\n",
    "lines_to_write = []\n",
    "top_10_classes = [\"Q11424\",\"Q5398426\",\"Q506240\",\"Q7777570\",\"Q21191270\",\"Q20667187\",\"Q229390\",\"Q43099869\",\"Q15416\",\"Q61220733\"]\n",
    "with open(f\"../output/instance_prediction_datasets/{property_label}.{orientation}.1250.tsv\",encoding=\"utf-8\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "    next(tsv_file)\n",
    "    for line in tsv_file:\n",
    "        for this_instance in instances[line[0]]:\n",
    "            if this_instance in top_10_classes:\n",
    "                lines_to_write.append(line)\n",
    "                classes_to_use.add(line[0])\n",
    "print(len(classes_to_use))\n",
    "# with open(f\"../output/instance_prediction_datasets/{property_label}.{orientation}.top10classes.tsv\", 'wt',encoding=\"utf-8\") as out_file:\n",
    "#     tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "#     tsv_writer.writerow([\"node\",\"nodeLabel\",\"prop\",\"nodeConnection\",\"connectionLabel\",\"nodeOrientation\"])\n",
    "#     tsv_writer.writerows(lines_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_to_write = []\n",
    "with open(\"../embeddings/profile_graph_embeddings.TransE.tsv\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\" \")\n",
    "    next(tsv_file)\n",
    "    for line in tsv_file:\n",
    "        if line[0] in classes_to_use:\n",
    "            instances_to_use = []\n",
    "            for this_instance in instances[line[0]]:\n",
    "                if this_instance in top_10_classes:\n",
    "                    instances_to_use.append(this_instance)\n",
    "            newline = line\n",
    "            newline.append(random.choice(instances_to_use))\n",
    "            lines_to_write.append(newline)\n",
    "with open(f\"../output/instance_prediction_datasets/{property_label}.{orientation}.embeddings_data.{limit}.tsv\", 'wt',encoding=\"utf-8\") as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow([\"Qnode\",\"pos1\",\"pos2\",\"pos3\",\"pos4\",\"pos5\",\"pos6\",\"pos7\",\"pos8\",\"pos9\",\"pos10\",\"pos11\",\"pos12\",\"pos13\",\"pos14\",\"pos15\",\"pos16\",\"pos17\",\"pos18\",\"pos19\",\"pos20\",\"pos21\",\"pos22\",\"pos23\",\"pos24\",\"pos25\",\"pos26\",\"pos27\",\"pos28\",\"pos29\",\"pos30\",\"pos31\",\"pos32\",\"pos33\",\"pos34\",\"pos35\",\"pos36\",\"pos37\",\"pos38\",\"pos39\",\"pos40\",\"pos41\",\"pos42\",\"pos43\",\"pos44\",\"pos45\",\"pos46\",\"pos47\",\"pos48\",\"pos49\",\"pos50\",\"pos51\",\"pos52\",\"pos53\",\"pos54\",\"pos55\",\"pos56\",\"pos57\",\"pos58\",\"pos59\",\"pos60\",\"pos61\",\"pos62\",\"pos63\",\"pos64\",\"pos65\",\"pos66\",\"pos67\",\"pos68\",\"pos69\",\"pos70\",\"pos71\",\"pos72\",\"pos73\",\"pos74\",\"pos75\",\"pos76\",\"pos77\",\"pos78\",\"pos79\",\"pos80\",\"pos81\",\"pos82\",\"pos83\",\"pos84\",\"pos85\",\"pos86\",\"pos87\",\"pos88\",\"pos89\",\"pos90\",\"pos91\",\"pos92\",\"pos93\",\"pos94\",\"pos95\",\"pos96\",\"pos97\",\"pos98\",\"pos99\",\"pos100\",\"Yval\"])\n",
    "    tsv_writer.writerows(lines_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SMOTE\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autogluon models\n",
    "all_data = TabularDataset(f'../output/instance_prediction_datasets/{property_label}.{orientation}.embeddings_data.{limit}.tsv')\n",
    "train_data = all_data[:708]\n",
    "test_data = all_data[708:]\n",
    "save_path = f'../embeddings/models/agModels.{property_label}.{orientation}.{limit}'\n",
    "label = 'Yval'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test data and evaluate models\n",
    "y_test = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])\n",
    "print(predictor.get_model_best())\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
