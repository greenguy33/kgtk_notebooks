{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac11cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from os.path import exists\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import numpy as np\n",
    "import json\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46b09f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P27': {'Q1426'}}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# define properties map to determine which qnodes and properties you want to predict the object for\n",
    "properties_map = {\"P1412\":{\"Q7747\",\"Q11116\"},\"P106\":{\"Q1701254\",\"Q5608\",\"Q207\",\"Q36153\",\"Q44437\",\"Q15935\",\"Q36159\",\"Q762\"},\"P19\":{\"Q180589\"},\"P102\":{\"Q22686\"},\"P641\":{\"Q44437\"},\"P180\":{\"Q12418\"},\"P136\":{\"Q175036\",\"Q506418\"},\"P186\":{\"Q18891156\"}}\n",
    "#properties_map = {\"P27\":{\"Q1426\"}}\n",
    "print(properties_map)\n",
    "print(len(properties_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a413bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_label=\"P27\"\n",
    "label = 'Yval'\n",
    "percent_train_data = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "797120f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading claims data for property P27 ...(may take some time depending on chosen property)\n",
      "P27 claims: 3975380\n",
      "Found 3678428 distinct nodes with at least one P27 relationship\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Read input file and create subject/object map\n",
    "all_node_maps = {}\n",
    "for property_label in properties_map:\n",
    "    all_lines = []\n",
    "    node_map = {}\n",
    "    print(\"Reading claims data for property\",property_label,\"...(may take some time depending on chosen property)\")\n",
    "    with open(f\"../data/propertiesSplit_final/claims.{property_label}.tsv\", encoding=\"utf-8\") as in_file:\n",
    "        tsv_reader = csv.reader(in_file, delimiter=\"\\t\")\n",
    "        header = next(tsv_reader)\n",
    "        for line in tsv_reader:\n",
    "            all_lines.append(line)\n",
    "            if line[0] in node_map:\n",
    "                node_map[line[0]].append(line[2])\n",
    "            else:\n",
    "                node_map[line[0]] = [line[2]]\n",
    "    print(property_label,\"claims:\",len(all_lines))\n",
    "    print(\"Found\",len(node_map),\"distinct nodes with at least one\",property_label,\"relationship\")\n",
    "    all_node_maps[property_label] = node_map\n",
    "print(len(all_node_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "251c7629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shuffled output file...\n",
      "Shuffled output written to claims.P828.tsv\n"
     ]
    }
   ],
   "source": [
    "# create shuffled output file\n",
    "for property_label in properties_map:\n",
    "    print(\"Creating shuffled output file...\")\n",
    "    random.shuffle(all_lines)\n",
    "    with open(f\"../data/propertiesSplit_final/claims.{property_label}.shuffled.tsv\", \"w\", encoding=\"utf-8\", newline='') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "        tsv_writer.writerow(header)\n",
    "        for line in all_lines:\n",
    "            tsv_writer.writerow(line)\n",
    "    print(\"Shuffled output written to claims.\"+property_label+\".tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfbc5765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the transE file...(this will take some time)\n",
      "P27\n",
      "Created training data file for property P27\n"
     ]
    }
   ],
   "source": [
    "# create embeddings-based training data\n",
    "# nodes_to_check=[\"Q16\"]\n",
    "transEheader = ['Qnode']\n",
    "for i in range(0,100):\n",
    "    transEheader.append(\"pos\"+str(i))\n",
    "transEheader.append(\"Yval\")\n",
    "file_map = {}\n",
    "for property_label in properties_map:\n",
    "    file1 = open(f\"../data/link_prediction_data/{property_label}.transE.tsv\", \"w\", encoding=\"utf-8\", newline='')\n",
    "    file2 = open(f\"../data/temp/custom_test_{property_label}.tsv\", 'w', encoding=\"utf-8\", newline='')\n",
    "    tsv_writer = csv.writer(file1, delimiter=\"\\t\")\n",
    "    temp_writer = csv.writer(file2, delimiter=\"\\t\")\n",
    "    tsv_writer.writerow(transEheader)\n",
    "    temp_writer.writerow(transEheader)\n",
    "    file_map[property_label] = [tsv_writer, temp_writer, file1, file2]\n",
    "\n",
    "# if (exists(f\"../data/link_prediction_data/{property_label}.transE.tsv\")):\n",
    "#     print(f\"File ../data/link_prediction_data/{property_label}.transE.tsv already exists!\")\n",
    "#else:\n",
    "print(\"Reading the transE file...(this will take some time)\")\n",
    "with open(f\"../embeddings/profile_graph_embeddings.transE.tsv\", encoding=\"utf-8\") as in_file:\n",
    "    tsv_reader = csv.reader(in_file, delimiter=\" \")\n",
    "    next(tsv_reader)\n",
    "    for line in tsv_reader:\n",
    "        for property_label in properties_map:\n",
    "            if line[0] in properties_map[property_label]:\n",
    "                file_map[property_label][1].writerow(line)\n",
    "                print(property_label)\n",
    "            elif line[0] in all_node_maps[property_label]:\n",
    "                this_arr = []\n",
    "                for elem in line:\n",
    "                    this_arr.append(elem)\n",
    "                randchoice = random.choice(all_node_maps[property_label][line[0]])\n",
    "                this_arr.append(randchoice)\n",
    "                file_map[property_label][0].writerow(this_arr)\n",
    "\n",
    "for property_label in file_map:\n",
    "    file_map[property_label][2].close()\n",
    "    file_map[property_label][3].close()\n",
    "\n",
    "print(\"Created training data file for property\",property_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "134de1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the transE file...(this will take some time)\n",
      "Created training data file for property P2139 with 9390 rows\n"
     ]
    }
   ],
   "source": [
    "# create embeddings-based training data for a single unit type\n",
    "nodes_to_check=[\"Q3895\"]\n",
    "if (exists(f\"../data/link_prediction_data/{property_label}.transE.tsv\")):\n",
    "    print(f\"File ../data/link_prediction_data/{property_label}.transE.tsv already exists!\")\n",
    "else:\n",
    "    transEheader = ['Qnode']\n",
    "    for i in range(0,100):\n",
    "        transEheader.append(\"pos\"+str(i))\n",
    "    transEheader.append(\"Yval\")\n",
    "    linecount = 0\n",
    "    print(\"Reading the transE file...(this will take some time)\")\n",
    "    with open(f\"../embeddings/profile_graph_embeddings.transE.tsv\", encoding=\"utf-8\") as in_file, open(f\"../data/link_prediction_data/{property_label}.transE.tsv\", \"w\", encoding=\"utf-8\", newline='') as out_file, open(f\"../data/temp/custom_test_{property_label}.tsv\", 'w', encoding=\"utf-8\", newline='') as temp_file:\n",
    "        tsv_reader = csv.reader(in_file, delimiter=\" \")\n",
    "        tsv_writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "        temp_writer = csv.writer(temp_file, delimiter=\"\\t\")\n",
    "        next(tsv_reader)\n",
    "        tsv_writer.writerow(transEheader)\n",
    "        temp_writer.writerow(transEheader)\n",
    "        for line in tsv_reader:\n",
    "            if line[0] in nodes_to_check:\n",
    "                temp_writer.writerow(line)\n",
    "            elif line[0] in node_map:\n",
    "                this_arr = []\n",
    "                for elem in line:\n",
    "                    this_arr.append(elem)\n",
    "                #randchoice = random.choice(node_map[line[0]])\n",
    "                for elem in random.sample(node_map[line[0]], len(node_map[line[0]])):\n",
    "                    unit = elem.split(\"Q\")\n",
    "                    if len(unit) > 1:\n",
    "                        if unit[1] == \"4917\":\n",
    "                            asnum = elem.replace(\"+\",\"\").split(\"[\")[0].split(\"Q\")[0]\n",
    "                            assert asnum.replace(\".\",\"\").replace(\"-\",\"\").isnumeric(), asnum\n",
    "                            this_arr.append(asnum)\n",
    "                            tsv_writer.writerow(this_arr)\n",
    "                            linecount += 1\n",
    "                            break\n",
    "\n",
    "    print(\"Created training data file for property\",property_label,\"with\",linecount,\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d9c4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the training/test data\n",
    "all_data = TabularDataset(f\"../data/link_prediction_data/{property_label}.transE.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81b9ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making train/test split for property P27 with 75 % training data...\n",
      "Data length: 3381439\n",
      "Training data size: 2536079\n",
      "Test data size: 845360\n"
     ]
    }
   ],
   "source": [
    "# make train/test split\n",
    "print(\"Making train/test split for property\",property_label,\"with\",str(percent_train_data)[2:],\"% training data...\")\n",
    "# limit data to some number of training rows\n",
    "short_data=all_data\n",
    "short_data = short_data\n",
    "print(\"Data length:\",int(len(short_data)))\n",
    "train_data = short_data[:int(len(short_data)*percent_train_data)]\n",
    "test_data = short_data[int(len(short_data)*percent_train_data):]\n",
    "print(\"Training data size:\",len(train_data))\n",
    "print(\"Test data size:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "457bb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count     2536079\n",
      "unique       2443\n",
      "top           Q30\n",
      "freq       320762\n",
      "Name: Yval, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# fit autogluon models\n",
    "#save_path = f'../embeddings/models/agModels.{property_label}.transE'\n",
    "save_path = f'../embeddings/models/KNNModels.{property_label}.transE'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())\n",
    "#predictor = TabularPredictor(label=label, path=save_path, learner_kwargs={\"label_count_threshold\":10}).fit(train_data, hyperparameters={'NN':{},'GBM':{},'XT':{},'KNN':{}})\n",
    "#print(\"Best model:\",predictor.get_model_best())\n",
    "#print(f\"Model saved to ../embeddings/models/agModels.{property_label}.transE\")\n",
    "neigh = KNeighborsClassifier(n_neighbors=25)\n",
    "#neigh = KNeighborsRegressor(n_neighbors=25)\n",
    "train_dropped = train_data.drop(columns=[\"Qnode\",\"Yval\"])\n",
    "y_val = train_data[\"Yval\"]\n",
    "predictor = neigh.fit(train_dropped, y_val)\n",
    "pickle.dump(predictor, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "499cb1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the 2 lines below to load the saved model; if the above cell has just been ran this is not necessary\n",
    "save_path = f'../embeddings/models/KNNModels.{property_label}.transE'\n",
    "# predictor = TabularPredictor.load(save_path)\n",
    "predictor = pickle.load(open(save_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions over test data...\")\n",
    "y_test = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])\n",
    "y_pred = list(predictor.predict(test_data_nolab))\n",
    "print(\"Predictions saved in y_pred variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d403b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = list(test_data[\"Qnode\"])\n",
    "correct = 0\n",
    "total = 0\n",
    "for index, entry in enumerate(entries):\n",
    "    prediction = y_pred[index]\n",
    "    if prediction in node_map[entry]:\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print(\"Overall accuracy:\",(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f13d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P27\n",
      "Data length: 3381439\n",
      "Q1426\n",
      "{'Q115': 0.96, 'Q32': 0.96, 'Q801': 0.96, 'Q974': 0.96, 'Q30': 0.92, 'Q191': 0.84, 'Q40': 0.76, 'Q39': 0.64}\n",
      "P102\n",
      "Data length: 350634\n",
      "Q22686\n",
      "{'Q849158': 0.96, 'Q29552': 0.56, 'Q29468': 0.48}\n",
      "P106\n",
      "Data length: 5852159\n",
      "Q15935\n",
      "{'Q10800557': 0.96, 'Q1259917': 0.96, 'Q1327329': 0.96, 'Q158852': 0.96, 'Q2340668': 0.96, 'Q33999': 0.96, 'Q3427922': 0.96, 'Q557880': 0.96, 'Q5716684': 0.96, 'Q855091': 0.96, 'Q183945': 0.92, 'Q55960555': 0.92, 'Q639669': 0.92, 'Q36834': 0.84, 'Q488205': 0.8}\n",
      "Q5608\n",
      "{'Q10800557': 0.96, 'Q183945': 0.96, 'Q18814623': 0.96, 'Q2526255': 0.96, 'Q28389': 0.96, 'Q3282637': 0.96, 'Q37226': 0.96, 'Q386854': 0.96, 'Q4351403': 0.96, 'Q488205': 0.96, 'Q49757': 0.96, 'Q55960555': 0.96, 'Q6168364': 0.96, 'Q753110': 0.96, 'Q765778': 0.96, 'Q36180': 0.92, 'Q639669': 0.92, 'Q177220': 0.88, 'Q36834': 0.88}\n",
      "Q762\n",
      "{'Q121594': 0.96, 'Q1234713': 0.96, 'Q14623005': 0.96, 'Q1622272': 0.96, 'Q170790': 0.96, 'Q177220': 0.96, 'Q205375': 0.96, 'Q214917': 0.96, 'Q21680731': 0.96, 'Q2374149': 0.96, 'Q250867': 0.96, 'Q3055126': 0.96, 'Q483501': 0.96, 'Q486748': 0.96, 'Q4964182': 0.96, 'Q49757': 0.96, 'Q593644': 0.96, 'Q639669': 0.96, 'Q901402': 0.96, 'Q1028181': 0.92, 'Q14915627': 0.92, 'Q36180': 0.92}\n",
      "Q36159\n",
      "{'Q5137571': 0.96, 'Q3665646': 0.040000000000000036}\n",
      "Q207\n",
      "{'Q17611899': 0.96, 'Q193391': 0.96, 'Q40348': 0.96, 'Q5137571': 0.96, 'Q82955': 0.96, 'Q11338576': 0.92, 'Q37226': 0.92, 'Q189290': 0.88, 'Q19204627': 0.88, 'Q10871364': 0.6}\n",
      "Q44437\n",
      "{'Q10833314': 0.96, 'Q128124': 0.96, 'Q578109': 0.96, 'Q7042855': 0.96, 'Q15077007': 0.92, 'Q2526255': 0.92, 'Q28389': 0.92, 'Q10798782': 0.88, 'Q3282637': 0.88, 'Q33999': 0.88, 'Q36180': 0.76}\n",
      "Q1701254\n",
      "{'Q12177489': 0.96, 'Q1368409': 0.96, 'Q15253558': 0.96, 'Q17502714': 0.96, 'Q1930187': 0.96, 'Q201788': 0.96, 'Q21198548': 0.96, 'Q2526255': 0.96, 'Q28389': 0.96, 'Q3499072': 0.96, 'Q3542795': 0.96, 'Q36834': 0.96, 'Q6625963': 0.96, 'Q7042855': 0.96, 'Q10798782': 0.92, 'Q2259451': 0.92, 'Q3282637': 0.92, 'Q33999': 0.92, 'Q10800557': 0.88}\n",
      "Q36153\n",
      "{'Q13382519': 0.96, 'Q16004471': 0.96, 'Q16145150': 0.96, 'Q177220': 0.96, 'Q193391': 0.96, 'Q2526255': 0.96, 'Q2865819': 0.96, 'Q3400985': 0.96, 'Q43845': 0.96, 'Q47064': 0.96, 'Q49757': 0.96, 'Q6625963': 0.96, 'Q6665249': 0.96, 'Q1028181': 0.92, 'Q10871364': 0.92, 'Q333634': 0.92, 'Q33999': 0.88, 'Q82955': 0.88}\n",
      "P136\n",
      "Data length: 850102\n",
      "Q175036\n",
      "{'Q166030': 0.96, 'Q16875712': 0.96, 'Q192110': 0.96, 'Q2839016': 0.96, 'Q2864737': 0.96, 'Q742333': 0.92, 'Q3374376': 0.88, 'Q128115': 0.84, 'Q191163': 0.8, 'Q134307': 0.76}\n",
      "Q506418\n",
      "{'Q20443008': 0.96, 'Q2137852': 0.96, 'Q2297927': 0.96, 'Q2421031': 0.96, 'Q622291': 0.96, 'Q859369': 0.96, 'Q1200678': 0.92, 'Q188473': 0.92, 'Q52207399': 0.92, 'Q860626': 0.88, 'Q130232': 0.8, 'Q157443': 0.8}\n",
      "P180\n",
      "Data length: 140347\n",
      "Q12418\n",
      "{'Q107425': 0.96, 'Q10791': 0.96, 'Q1144593': 0.96, 'Q3010': 0.96, 'Q3031': 0.96, 'Q3314483': 0.96, 'Q345': 0.96, 'Q35872': 0.96, 'Q434290': 0.96, 'Q44248': 0.96, 'Q467': 0.96, 'Q46750': 0.96, 'Q506': 0.96, 'Q536168': 0.96, 'Q571': 0.96, 'Q8018': 0.96, 'Q10884': 0.92, 'Q726': 0.88, 'Q8441': 0.84}\n",
      "P186\n",
      "Data length: 351984\n",
      "Q18891156\n",
      "{'Q389782': 0.96, 'Q4259259': 0.96, 'Q175166': 0.92, 'Q1348059': 0.76, 'Q12321255': 0.72, 'Q296955': 0.6799999999999999}\n",
      "P641\n",
      "Data length: 1398898\n",
      "Q44437\n",
      "{'Q11419': 0.96, 'Q163770': 0.96, 'Q178678': 0.96, 'Q36389': 0.96, 'Q36908': 0.96, 'Q847': 0.96, 'Q114466': 0.92, 'Q131359': 0.72, 'Q41323': 0.6}\n",
      "P1412\n",
      "Data length: 855508\n",
      "Q11116\n",
      "{'Q143': 0.96, 'Q7976': 0.96, 'Q1860': 0.07999999999999996}\n",
      "Q7747\n",
      "{'Q150': 0.96, 'Q188': 0.96, 'Q256': 0.96, 'Q5287': 0.96, 'Q7850': 0.96, 'Q9035': 0.96, 'Q1860': 0.84, 'Q7737': 0.4}\n",
      "P1971\n",
      "Data length: 21117\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsRegressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-80123def94db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#print(predictor.get_model_names())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpreddata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../data/temp/custom_test_{property_label}.tsv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Qnode\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreddata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;31m#probabilities_dict = probabilities.to_dict()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#probabilities = predictor.predict(preddata)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNeighborsRegressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "numeric_property_labels = [\"P1971\",\"P2067\",\"P2139\",\"P2250\",\"P2927\",\"P3001\"]\n",
    "property_labels = [\"P27\",\"P102\",\"P106\",\"P136\",\"P180\",\"P186\",\"P641\",\"P1412\"]\n",
    "all_properties = [\"P27\",\"P102\",\"P106\",\"P136\",\"P180\",\"P186\",\"P641\",\"P1412\",\"P1971\",\"P2067\",\"P2139\",\"P2250\",\"P2927\",\"P3001\"]\n",
    "\n",
    "for property_label in numeric_property_labels:\n",
    "    nodes_to_check = []\n",
    "    print(property_label)\n",
    "    \n",
    "    all_data = TabularDataset(f\"../data/link_prediction_data/{property_label}.transE.tsv\")\n",
    "    print(\"Data length:\",int(len(all_data)))\n",
    "    train_data = all_data[:int(len(all_data)*percent_train_data)]\n",
    "    y_val = train_data[\"Yval\"]\n",
    "    \n",
    "    save_path = f'../embeddings/models/KNNModels.{property_label}.transE'\n",
    "    predictor = pickle.load(open(save_path, 'rb'))\n",
    "    \n",
    "    with open(f\"../data/temp/custom_test_{property_label}.tsv\", encoding=\"utf-8\") as in_file:\n",
    "            tsv_reader = csv.reader(in_file, delimiter=\"\\t\")\n",
    "            next(tsv_reader)\n",
    "            for line in tsv_reader:\n",
    "                nodes_to_check.append(line[0])\n",
    "\n",
    "    results = {}\n",
    "    for node in nodes_to_check:\n",
    "        results[node] = {}\n",
    "\n",
    "    y_val_ordered = sorted(set(y_val))\n",
    "\n",
    "    preddata = TabularDataset(f\"../data/temp/custom_test_{property_label}.tsv\").drop(columns=[label,\"Qnode\"])\n",
    "    #probabilities = predictor.predict_proba(preddata)\n",
    "    probabilities = predictor.predict(preddata)\n",
    "\n",
    "    for ind, node in enumerate(nodes_to_check):\n",
    "        with open(f\"../../surprising-facts/distance_results/profile.transE.supervised.lhs/results_{node}_{property_label}.tsv\", \"w\", encoding=\"utf-8\", newline='') as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "            index = ind\n",
    "            res_map = {}\n",
    "            for in2, val in enumerate(probabilities[index]):\n",
    "                if val > 0:\n",
    "                    res_map[y_val_ordered[in2]] = 1-val\n",
    "            print(node)\n",
    "            print({k: v for k, v in sorted(res_map.items(), key=lambda item: item[1], reverse=True)})\n",
    "            for key in res_map:\n",
    "                tsv_writer.writerow([key, res_map[key]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa52dcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q13381572', 'Q6581097', 'Q37073', 'Q932650', 'Q860450', 'Q49085', 'Q3282637', 'Q22662561', 'Q1111310', 'Q2526255', 'Q36834', 'Q177220', 'Q11338576', 'Q45', 'Q50001', 'Q13474373', 'Q8341', 'Q10798782', 'Q989442', 'Q43845', 'Q183387', 'Q15295720', 'Q104238320', 'Q3724813', 'Q12718299', 'Q1320315', 'Q28389', 'Q2405480', 'Q11296761', 'P30', 'Q15982795', 'Q145', 'Q33999', 'Q4610556', 'Q11696', 'Q34', 'Q23845879', 'Q19204627', 'Q67175841', 'Q865851', 'Q5716684', 'Q16947675', 'Q16', 'Q668', 'Q82955', 'Q2742632', 'Q45981', 'Q327591', 'Q655286', 'Q169470', 'Q6581072', 'Q465501', 'Q1371091', 'Q41323', 'Q40', 'Q10497074', 'Q1414443', 'Q488205', 'Q9268', 'Q519076', 'Q30', 'Q11607585', 'Q11124885', 'Q60', 'Q15966504', 'Q27'}\n"
     ]
    }
   ],
   "source": [
    "# read second benchmark facts\n",
    "import csv\n",
    "count = 0\n",
    "properties_map = {}\n",
    "all_answers = set()\n",
    "with open(f\"../wd_bm_2.csv\") as in_file:\n",
    "    csv_reader = csv.reader(in_file, delimiter=\",\")\n",
    "    next(csv_reader)\n",
    "    for line in csv_reader:\n",
    "        if line[3] != \"\":\n",
    "            split = \"|\".join(line[3].split(\",\")).split(\"|\")\n",
    "            for fact in split:\n",
    "                if \"cent\" not in fact and \"_\" not in fact and fact != \"\":\n",
    "                    factsplit = fact.split(\"=\")\n",
    "                    count += 1\n",
    "                    if factsplit[0] in properties_map:\n",
    "                        properties_map[factsplit[0]].add(line[1])\n",
    "                    else:\n",
    "                        properties_map[factsplit[0]] = {line[1]}\n",
    "                    all_answers.add(factsplit[1])\n",
    "print(all_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41991fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P1971': {'Q5_P1971_3.0-4.0__'}, 'P2067': {'Q5_P2067_210.0-240.0__Q100995'}, 'P2139': {'Q4830453_P2139_6764000000.0-217267000000.0__Q4916'}, 'P2250': {'Q3624078_P2250_73.861-76.577__Q577'}, 'P2927': {'Q3624078_P2927_2.6-5.7__Q11229'}, 'P3001': {'Q3624078_P3001_62.5-65.0__Q24564698'}}\n",
      "P2250 Q3624078_P2250_73.861-76.577__Q577\n",
      "P2927 Q3624078_P2927_2.6-5.7__Q11229\n",
      "P2139 Q4830453_P2139_6764000000.0-217267000000.0__Q4916\n",
      "P3001 Q3624078_P3001_62.5-65.0__Q24564698\n",
      "P2067 Q5_P2067_210.0-240.0__Q100995\n",
      "P1971 Q5_P1971_3.0-4.0__\n"
     ]
    }
   ],
   "source": [
    "# scan prediction files and add embedding results\n",
    "properties = {}\n",
    "\n",
    "file_map = {}\n",
    "properties_map = [\"P1971\", \"P2067\", \"P2139\", \"P2250\", \"P2927\", \"P3001\"]\n",
    "for property_label in properties_map:\n",
    "    file1 = open(f\"../data/results/bm1/embeddings/bm1_results.{property_label}.embeddings.tsv\", \"w\", encoding=\"utf-8\", newline='')\n",
    "    tsv_writer = csv.writer(file1, delimiter=\"\\t\")\n",
    "    file_map[property_label] = [tsv_writer, file1]\n",
    "    properties[property_label] = set()\n",
    "    with open(f\"../data/results/bm1/bm1_results.{property_label}.tsv\") as in_file:\n",
    "        tsv_reader = csv.reader(in_file, delimiter=\"\\t\")\n",
    "        for line in tsv_reader:\n",
    "            properties[property_label].add(line[2])\n",
    "print(properties)\n",
    "    \n",
    "with open(f\"../embeddings/profile_graph_embeddings.TransE.tsv\") as transE:\n",
    "    tsv_reader = csv.reader(transE, delimiter=\" \")\n",
    "    header = next(tsv_reader)\n",
    "    for line in tsv_reader:\n",
    "        for property_label in properties:\n",
    "            for cla in properties[property_label]:\n",
    "                if line[0] == cla:\n",
    "                    print(property_label, cla)\n",
    "                    file_map[property_label][0].writerow(line)\n",
    "\n",
    "for property_label in properties_map:\n",
    "    file_map[property_label][1].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce455b93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45daa96d5b06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mall_answers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Q34174\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0manswerfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../embeddings/bm1.answers.embeddings.custom.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtsv_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswerfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../embeddings/profile_graph_embeddings.TransE.tsv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "properties = {}\n",
    "\n",
    "#all_answers = [\"Q1860\",\"Q188\",\"Q7737\",\"Q9027\",\"Q1321\",\"Q10800557\",\"Q36180\",\"Q10798782\",\"Q947873\",\"Q3282637\",\"Q258\",\"Q39\",\"Q884\",\"Q142\",\"Q30\",\"Q60\",\"Q90\",\"Q220\",\"Q1055\",\"Q84\",\"Q482980\",\"Q3282637\",\"Q131524\",\"Q488205\",\"Q1028181\",\"Q14089670\",\"Q82955\",\"Q189290\",\"Q1028181\",\"Q177220\",\"Q4610556\",\"Q2405480\",\"Q131524\",\"Q488205\",\"Q5716684\",\"Q29552\",\"Q29468\",\"Q79854\",\"Q7320\",\"Q49768\",\"Q639669\",\"Q2405480\",\"Q36180\",\"Q82955\",\"Q10873124\",\"Q41323\",\"Q5369\",\"Q838089\",\"Q32112\",\"Q5378\",\"Q42973\",\"Q2526255\",\"Q82955\",\"Q177220\",\"Q2309784\",\"Q10798782\",\"Q3665646\",\"Q28389\",\"Q1650915\",\"Q36180\",\"Q193391\",\"Q350979\",\"Q593644\",\"Q1028181\",\"Q81096\",\"Q9027\",\"Q1860\",\"Q7737\",\"Q150\",\"Q188\",\"Q12280\",\"Q8502\",\"Q527\",\"Q107425\",\"Q345\",\"Q742333\",\"Q134307\",\"Q1935974\",\"Q191163\",\"Q192110\",\"Q389782\",\"Q175166\",\"Q296955\",\"Q11472\",\"Q12321255\",\"Q4259259\",\"Q52207399\",\"Q860626\",\"Q157394\",\"Q130232\",\"Q842256\",\"Q5_P1412_Q1860\",\"Q5_P1412_Q188\",\"Q5_P1412_Q7737\",\"Q5_P1412_Q9027\",\"Q5_P1412_Q1321\",\"Q5_P106_Q10800557\",\"Q5_P106_Q36180\",\"Q5_P106_Q10798782\",\"Q5_P106_Q947873\",\"Q5_P106_Q3282637\",\"Q5_P27_Q258\",\"Q5_P27_Q39\",\"Q5_P27_Q884\",\"Q5_P27_Q142\",\"Q5_P27_Q30\",\"Q5_P1971_0.0-2.0__\",\"Q5_P1971_2.0-3.0__\",\"Q5_P1971_3.0-4.0__\",\"Q5_P1971_4.0-210.0__\",\"Q5_P19_Q60\",\"Q5_P19_Q90\",\"Q5_P19_Q220\",\"Q5_P19_Q1055\",\"Q5_P19_Q84\",\"Q5_P106_Q482980\",\"Q5_P106_Q3282637\",\"Q5_P106_Q131524\",\"Q5_P106_Q488205\",\"Q5_P106_Q1028181\",\"Q5_P106_Q14089670\",\"Q5_P106_Q82955\",\"Q5_P106_Q189290\",\"Q5_P106_Q1028181\",\"Q5_P106_Q177220\",\"Q5_P106_Q4610556\",\"Q5_P106_Q2405480\",\"Q5_P106_Q131524\",\"Q5_P106_Q488205\",\"Q5_P106_Q5716684\",\"Q5_P2067_1.0-181.0__Q100995\",\"Q5_P2067_181.0-195.0__Q100995\",\"Q5_P2067_195.0-210.0__Q100995\",\"Q5_P2067_210.0-240.0__Q100995\",\"Q5_P2067_240.0-555.0__Q100995\",\"Q5_P102_Q29552\",\"Q5_P102_Q29468\",\"Q5_P102_Q79854\",\"Q5_P102_Q7320\",\"Q5_P102_Q49768\",\"Q5_P106_Q639669\",\"Q5_P106_Q2405480\",\"Q5_P106_Q36180\",\"Q5_P106_Q82955\",\"Q5_P106_Q10873124\",\"Q5_P641_Q41323\",\"Q5_P641_Q5369\",\"Q5_P641_Q838089\",\"Q5_P641_Q32112\",\"Q5_P641_Q5378\",\"Q5_P106_Q42973\",\"Q5_P106_Q2526255\",\"Q5_P106_Q82955\",\"Q5_P106_Q177220\",\"Q5_P106_Q2309784\",\"Q5_P106_Q10798782\",\"Q5_P106_Q3665646\",\"Q5_P106_Q28389\",\"Q5_P106_Q1650915\",\"Q5_P106_Q36180\",\"Q5_P106_Q193391\",\"Q5_P106_Q350979\",\"Q5_P106_Q593644\",\"Q5_P106_Q1028181\",\"Q5_P106_Q81096\",\"Q5_P1412_Q9027\",\"Q5_P1412_Q1860\",\"Q5_P1412_Q7737\",\"Q5_P1412_Q150\",\"Q5_P1412_Q188\",\"Q3624078_P2250_76.59756-85.41707__Q577\",\"Q3624078_P2250_63.33-69.862__Q577\",\"Q3624078_P2250_70.197-73.82683__Q577\",\"Q3624078_P2250_51.835-63.238__Q577\",\"Q3624078_P2250_73.861-76.577__Q577\",\"Q3624078_P3001_55.0-60.0__Q24564698\",\"Q3624078_P3001_62.5-65.0__Q24564698\",\"Q3624078_P3001_60.0-62.5__Q24564698\",\"Q3624078_P3001_65.25-67.0__Q24564698\",\"Q3624078_P2927_8.4-27.9__Q11229\",\"Q3624078_P2927_1.5-2.5__Q11229\",\"Q3624078_P2927_0.0-0.2__Q11229\",\"Q3624078_P2927_2.6-5.7__Q11229\",\"Q3624078_P2927_0.3-1.444__Q11229\",\"Q3305213_P180_Q12280\",\"Q3305213_P180_Q8502\",\"Q3305213_P180_Q527\",\"Q3305213_P180_Q107425\",\"Q3305213_P180_Q345\",\"Q3305213_P136_Q742333\",\"Q3305213_P136_Q134307\",\"Q3305213_P136_Q1935974\",\"Q3305213_P136_Q191163\",\"Q3305213_P136_Q192110\",\"Q3305213_P186_Q389782\",\"Q3305213_P186_Q175166\",\"Q3305213_P186_Q296955\",\"Q3305213_P186_Q11472\",\"Q3305213_P186_Q12321255\",\"Q3305213_P186_Q4259259\",\"Q11424_P136_Q52207399\",\"Q11424_P136_Q860626\",\"Q11424_P136_Q157394\",\"Q11424_P136_Q130232\",\"Q11424_P136_Q842256\",\"Q4830453_P2139_1.0-108589000.0__Q4916\",\"Q4830453_P2139_438000000.0-1590000000.0__Q4916\",\"Q4830453_P2139_113000000.0-427800000.0__Q4916\",\"Q4830453_P2139_6764000000.0-217267000000.0__Q4916\",\"Q4830453_P2139_1610000000.0-6745000000.0__Q4916\"]\n",
    "all_answers = [\"Q34174\",\"Q2982063\",\"Q66650486\",\"Q14955281\",\"Q88400354\"]\n",
    "answerfile = open(f\"../embeddings/bm1.answers.embeddings.custom.tsv\", \"w\", encoding=\"utf-8\", newline='')\n",
    "tsv_writer = csv.writer(answerfile, delimiter=\"\\t\")\n",
    "\n",
    "with open(f\"../embeddings/profile_graph_embeddings.TransE.tsv\") as transE:\n",
    "    tsv_reader = csv.reader(transE, delimiter=\" \")\n",
    "    header = next(tsv_reader)\n",
    "    for line in tsv_reader:\n",
    "        if line[0] in all_answers:  \n",
    "            tsv_writer.writerow(line)\n",
    "    \n",
    "answerfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db1b1f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What language(s) does Vladimir Putin speak, write, or sign with?\n",
      "{'Q9027': [0, 0]}\n",
      "What occupation(s) has John Oliver had?\n",
      "{'Q10800557': [0.88, 1]}\n",
      "Please select the country or countries in which Roger Federer possesses citizenship\n",
      "How many children does Arnold Schwarzenegger have?\n",
      "{'Q5_P1971_4.0-210.0__': [0, 0]}\n",
      "What is Boris Johnson's place of birth?\n",
      "What occupation(s) has Eminem had?\n",
      "{'Q482980': [0, 0]}\n",
      "What occupation(s) has George W. Bush had?\n",
      "{'Q14089670': [0, 0]}\n",
      "What occupation(s) has Beyoncé had?\n",
      "{'Q4610556': [0, 0], 'Q2405480': [0, 0]}\n",
      "What is Donald Trump's mass in pounds circa. 2019?\n",
      "What political party/parties has Donald Trump been a member of?\n",
      "What occupation(s) has John Cena had?\n",
      "{'Q36180': [0.76, 1]}\n",
      "What sport(s) has John Cena participated in?\n",
      "{'Q41323': [0.6, 1]}\n",
      "What occupation(s) has Kanye West had?\n",
      "What occupation(s) has LeBron James had?\n",
      "{'Q28389': [0, 0]}\n",
      "What occupation(s) did Leonardo Da Vinci have?\n",
      "{'Q350979': [0, 0]}\n",
      "What language(s) did Ruth Bader Ginsburg speak, write, or sign?\n",
      "{'Q9027': [0, 0]}\n",
      "What is the life expectancy in years of Australia circa. 2016?\n",
      "What is the retirement age in Colombia? The answer for either men or women will be accepted.\n",
      "{'Q3624078_P3001_60.0-62.5__Q24564698': [0, 0]}\n",
      "What percentage of the territory of Canada inside its coast line and international boundaries is water?\n",
      "Which entity or entities is/are depicted in the painting \"Mona Lisa\"?\n",
      "{'Q12280': [0, 0]}\n",
      "Which genre(s) is the painting \"Guernica\" considered?\n",
      "Which materials were used in the painting \"The Scream\"?\n",
      "{'Q389782': [0.96, 5], 'Q175166': [0.92, 4]}\n",
      "Which genre(s) is the film \"The Princess Bride\" considered?\n",
      "What was the total revenue in euros of the business \"Adidas\" circa. 2014?\n",
      "{'Q4830453_P2139_6764000000.0-217267000000.0__Q4916': [1.0, 1]}\n",
      "17\n",
      "Final MRR:\n",
      "0.26176470588235295\n"
     ]
    }
   ],
   "source": [
    "# get MRR score from distance files\n",
    "\n",
    "with open(\"../wd_json_trivia.qnodes.json\", 'r') as f:\n",
    "    questions = json.load(f)\n",
    "    \n",
    "mrr_scores = []\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "    for answer in q[\"answers\"]:\n",
    "        ans_fact_ids = []\n",
    "        for qnode in answer[\"qnodes\"]:\n",
    "            fact_id = \"{}_{}_{}\".format(q[\"class\"], q[\"property\"], qnode)\n",
    "            if q[\"wd_units\"] is not None:\n",
    "                fact_id += \"__\" + q[\"wd_units\"]\n",
    "            ans_fact_ids.append(fact_id)\n",
    "        answer[\"fact_ids\"] = ans_fact_ids\n",
    "        \n",
    "# assign outliers\n",
    "for q in questions:\n",
    "    surprise_score = []\n",
    "    for ans in q[\"answers\"]:\n",
    "        surprise_score.append(ans[\"gt_surprise\"])\n",
    "    outlier_scores = sorted(surprise_score, reverse=True)[:2]\n",
    "    for ans in q[\"answers\"]:\n",
    "        if ans[\"gt_surprise\"] in outlier_scores:\n",
    "            ans[\"outlier\"] = True\n",
    "        else:\n",
    "            ans[\"outlier\"] = False\n",
    "        \n",
    "for q in questions:\n",
    "    print(q[\"lexicalized\"])\n",
    "    keystring = \"qnodes\"\n",
    "    if q[\"is_numeric_answer\"]:\n",
    "        keystring = \"fact_ids\"\n",
    "    src_ent = q[\"entity\"]\n",
    "    edge = q[\"property\"]\n",
    "\n",
    "    targets = {}\n",
    "    for ans in q[\"answers\"]:\n",
    "        if ans[\"truth_value_fact_checked\"] == True:\n",
    "            if ans[\"outlier\"] == True:\n",
    "                for qnode in ans[keystring]:\n",
    "                    targets[qnode] = [0,0]\n",
    "\n",
    "    if len(targets) > 0:\n",
    "        file = f\"../../surprising-facts/distance_results/profile.transE.supervised.lhs/results_{src_ent}_{edge}.tsv\"\n",
    "        count = 0\n",
    "        with open(file, \"r\") as in_file:\n",
    "            reader = csv.reader(in_file, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if row[0] in targets:\n",
    "                    targets[row[0]][0] = float(row[1])\n",
    "                    targets[row[0]][1] += 1\n",
    "        with open(file, \"r\") as in_file:\n",
    "            reader = csv.reader(in_file, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                dist = float(row[1])\n",
    "                for tar in targets:\n",
    "                    if row[0] != tar:\n",
    "                        if dist < targets[tar][0]:\n",
    "                            targets[tar][1] += 1\n",
    "        print(targets)\n",
    "        for tar in targets:\n",
    "            if targets[tar][1] == 0:\n",
    "                mrr_scores.append(0)\n",
    "            else:\n",
    "                mrr_scores.append(1/targets[tar][1])\n",
    "\n",
    "print(len(mrr_scores))\n",
    "print(\"Final MRR:\")\n",
    "print(mean(mrr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ddef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
