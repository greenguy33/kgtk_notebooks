{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "property_label = \"P19\"\n",
    "# should be \"subjects\" or \"objects\"\n",
    "orientation = \"objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct classes:  1260\n",
      "making predictions...\n",
      "retrieving correct answers...\n",
      "retrieving scores...\n",
      "final avg. score:  0.002425079365079365\n",
      "Q21278897 266 0.0\n",
      "Q4533081 166 0.0\n",
      "Q18142 116 0.0\n",
      "Q607241 84 0.005833333333333333\n",
      "Q394067 67 0.0\n",
      "Q82117 55 0.0\n",
      "Q7366 50 0.0\n",
      "Q81058955 32 0.0\n",
      "Q2384959 31 0.0\n",
      "Q17633526 25 0.0\n",
      "Q33388604 25 0.0\n",
      "Q521972 23 0.0\n",
      "Q28640 18 0.0\n",
      "Q1344 18 0.0\n",
      "Q3802482 17 0.0\n",
      "Q231002 16 0.0\n",
      "Q83328 15 0.0\n",
      "Q2588070 12 0.0\n",
      "Q4209223 12 0.0\n",
      "Q899409 12 0.0\n",
      "Q334383 11 0.0\n",
      "Q20867284 10 0.04096000000000001\n",
      "Q2775 9 0.0\n",
      "Q1707610 8 0.0\n",
      "Q22947 8 0.0\n",
      "Q17624511 7 0.09799999999999998\n",
      "Q1365179 5 0.0\n",
      "Q14839548 5 0.0\n",
      "Q4989906 5 0.0\n",
      "Q3678424 4 0.36749999999999994\n",
      "Q2623243 4 0.0\n",
      "Q6502866 4 0.0\n",
      "Q15632166 4 0.0\n",
      "Q33513247 4 0.0\n",
      "Q47012103 4 0.0\n",
      "Q16970 4 0.0\n",
      "Q160742 4 0.0\n",
      "Q4057659 4 0.0\n",
      "Q47150325 4 0.0\n",
      "Q53060 4 0.0\n",
      "Q1267889 4 0.0\n",
      "Q25379 3 0.0\n",
      "Q11879590 3 0.0\n",
      "Q207628 3 0.0\n",
      "Q2116450 3 0.0\n",
      "Q1575478 3 0.0\n",
      "Q29586452 3 0.0\n",
      "Q744099 3 0.0\n",
      "Q4156067 3 0.0\n",
      "Q1406988 2 0.0\n",
      "Q925455 2 0.0\n",
      "Q3931974 2 0.0\n",
      "Q190157 2 0.0\n",
      "Q1970243 2 0.0\n",
      "Q28107315 2 0.0\n",
      "Q2617 2 0.0\n",
      "Q913035 2 0.0\n",
      "Q133311 2 0.0\n",
      "Q369385 2 0.0\n",
      "Q1177609 2 0.0\n",
      "Q5916199 1 0.0\n",
      "Q59081206 1 0.0\n",
      "Q1286517 1 0.0\n",
      "Q6266 1 0.0\n",
      "Q2578218 1 0.0\n",
      "Q543813 1 0.0\n",
      "Q828485 1 0.0\n",
      "Q13433827 1 0.0\n",
      "Q385422 1 0.0\n",
      "Q2592651 1 0.0\n",
      "Q101352 1 0.0\n",
      "Q263274 1 0.0\n",
      "Q170584 1 0.0\n",
      "Q2190251 1 0.0\n",
      "Q15310171 1 0.0\n",
      "Q1130279 1 0.0\n",
      "Q21286738 1 0.0\n",
      "Q219715 1 0.0\n",
      "Q30058680 1 0.0\n",
      "Q39594 1 0.0\n",
      "Q27095213 1 0.0\n",
      "Q7832362 1 0.0\n",
      "Q1143410 1 0.0\n",
      "Q3248048 1 0.0\n",
      "Q18071983 1 0.0\n",
      "Q190429 1 0.0\n",
      "Q618779 1 0.0\n",
      "Q6881511 1 0.0\n",
      "Q21672098 1 0.0\n",
      "Q3591895 1 0.0\n",
      "Q13417114 1 0.0\n",
      "Q1530361 1 0.0\n",
      "Q1497375 1 0.0\n",
      "Q64913082 1 0.0\n",
      "Q13439060 1 0.0\n",
      "Q1021233 1 0.0\n",
      "Q26879769 1 0.0\n",
      "Q5116872 1 0.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import statistics\n",
    "\n",
    "node_subject_props = {}\n",
    "node_object_props = {}\n",
    "dis_class = set()\n",
    "tsv_file = open(f'../output/instance_prediction_datasets/{property_label}.{orientation}.1250.tsv',encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "all_node_subject_props = []\n",
    "all_node_object_props = []\n",
    "for line in read_tsv:\n",
    "    dis_class.add(line[0])\n",
    "#     if line[5] == \"subject\":\n",
    "#         all_node_subject_props.append(line[2])\n",
    "#         if line[0] in node_subject_props:\n",
    "#             node_subject_props[line[0]].append(line[2])\n",
    "#         else:\n",
    "#             node_subject_props[line[0]] = [line[2]]\n",
    "#     elif line[5] == \"object\":\n",
    "#         all_node_object_props.append(line[2])\n",
    "#         if line[0] in node_object_props:\n",
    "#             node_object_props[line[0]].append(line[2])\n",
    "#         else:\n",
    "#             node_object_props[line[0]] = [line[2]]\n",
    "\n",
    "# print(\"node subject props size: \", len(all_node_subject_props)/len(dis_class))\n",
    "# print(\"distinct node subject props: \", len(set(all_node_subject_props)))\n",
    "# print(\"node object props size: \", len(all_node_object_props)/len(dis_class))\n",
    "# print(\"distinct node object props: \", len(set(all_node_object_props)))\n",
    "\n",
    "print(\"distinct classes: \", len(dis_class))\n",
    "\n",
    "print(\"making predictions...\")\n",
    "#guesses = predictWithConstraints(dis_class, node_subject_props, node_object_props)\n",
    "guesses = predictWithEmbeddings(dis_class)\n",
    "\n",
    "print(\"retrieving correct answers...\")\n",
    "correct_answers = getCorrectAnswers(list(dis_class))\n",
    "\n",
    "print(\"retrieving scores...\")\n",
    "scores = []\n",
    "guess_efficacy = {}\n",
    "for elem in guesses:\n",
    "    this_score = score(guesses[elem], correct_answers[elem])\n",
    "    scores.append(this_score)\n",
    "    if guesses[elem] in guess_efficacy:\n",
    "        guess_efficacy[guesses[elem]][0] += 1\n",
    "        guess_efficacy[guesses[elem]][1] += this_score\n",
    "    else:\n",
    "        guess_efficacy[guesses[elem]] = [1, this_score]\n",
    "print(\"final avg. score: \", statistics.mean(scores))\n",
    "for k,v in sorted(guess_efficacy.items(), key=lambda p:p[1], reverse=True):\n",
    "    print(k,v[0],(v[1]/v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score P31 datasets\n",
    "import csv\n",
    "\n",
    "direct_subclasses = {}\n",
    "direct_superclasses = {}\n",
    "\n",
    "tsv_file = open('../derived.P279.tsv/derived.P279.tsv',encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[1] not in direct_superclasses:\n",
    "        direct_superclasses[line[1]] = [line[3]]\n",
    "    else:\n",
    "        direct_superclasses[line[1]].append(line[3])\n",
    "    if line[3] not in direct_subclasses:\n",
    "        direct_subclasses[line[3]] = [line[1]]\n",
    "    else:\n",
    "        direct_subclasses[line[3]].append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "\n",
    "def getCorrectAnswers(candidates):\n",
    "    answers = {}\n",
    "#     with open('../derived.P31.tsv/derived.P31.tsv',encoding=\"utf-8\") as f:\n",
    "#         s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "#         while len(candidates) != 0:\n",
    "#             line = s.readline()\n",
    "#             for candidate in candidates:\n",
    "#                 if str.encode(\"\\t\"+candidate+\"\\t\") in line:\n",
    "#                     str1 = line.decode(\"utf-8\")\n",
    "#                     split = str1.split(\"\\t\")\n",
    "#                     answer = split[-1].split(\"\\n\")[0]\n",
    "#                     answers[candidate] = answer\n",
    "#                     candidates.remove(candidate)\n",
    "    tsv_file = open(f'../output/allConstraintsAnalysis_Final/instances/instances.{orientation}.{property_label}.tsv', encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    for line in read_tsv:\n",
    "        answers[line[0]] = line[1]\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (guess, correct):\n",
    "    if guess == correct: \n",
    "        return 1\n",
    "    else:\n",
    "        subclasses = []\n",
    "        superclasses = []\n",
    "        if guess in direct_subclasses:\n",
    "            subclasses = direct_subclasses[guess]\n",
    "        if guess in direct_superclasses:\n",
    "            superclasses = direct_superclasses[guess]\n",
    "        for i in range(1,6):\n",
    "            new_subclasses = []\n",
    "            new_superclasses = []\n",
    "            for subc in subclasses:\n",
    "                if subc == correct:\n",
    "                    if i <= 3:\n",
    "                        return .7**i\n",
    "                    else:\n",
    "                        return .8**i\n",
    "                else:\n",
    "                    if subc in direct_subclasses:\n",
    "                        for new_sub in direct_subclasses[subc]:\n",
    "                            new_subclasses.append(new_sub)\n",
    "            for supc in superclasses:\n",
    "                if supc == correct:\n",
    "                    if i <= 3:\n",
    "                        return .7**i\n",
    "                    else:\n",
    "                        return .8**i\n",
    "                else:\n",
    "                    if supc in direct_superclasses:\n",
    "                        for new_sup in direct_superclasses[supc]:\n",
    "                            new_superclasses.append(new_sup)\n",
    "            subclasses = new_subclasses\n",
    "            superclasses = new_superclasses\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load constraint values\n",
    "typeConstraints = {}\n",
    "tsv_file = open(f'../data/property_constraints/all_type_constraints.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[0].replace(\"http://www.wikidata.org/entity/\",\"\") in typeConstraints:\n",
    "        typeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")].append(line[2].replace(\"http://www.wikidata.org/entity/\",\"\"))\n",
    "    else:\n",
    "        typeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")] = [line[2].replace(\"http://www.wikidata.org/entity/\",\"\")]\n",
    "\n",
    "valueTypeConstraints = {}\n",
    "tsv_file = open(f'../data/property_constraints/all_value_type_constraints.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[0].replace(\"http://www.wikidata.org/entity/\",\"\") in valueTypeConstraints:\n",
    "        valueTypeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")].append(line[2].replace(\"http://www.wikidata.org/entity/\",\"\"))\n",
    "    else:\n",
    "        valueTypeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")] = [line[2].replace(\"http://www.wikidata.org/entity/\",\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithConstraints(dis_class, node_subject_props, node_object_props):\n",
    "    final_guesses = {}\n",
    "    for node in dis_class:\n",
    "        all_class_votes = {}\n",
    "        if node in node_subject_props:\n",
    "            subject_props = node_subject_props[node]\n",
    "            for prop in subject_props:\n",
    "                if prop in typeConstraints:\n",
    "                    for constraint in typeConstraints[prop]:\n",
    "                        if constraint in all_class_votes:\n",
    "                            all_class_votes[constraint] += 1\n",
    "                        else:\n",
    "                            all_class_votes[constraint] = 1\n",
    "        if node in node_object_props:\n",
    "            object_props = node_object_props[node]\n",
    "            for prop in object_props:\n",
    "                if prop in valueTypeConstraints:\n",
    "                    for constraint in valueTypeConstraints[prop]:\n",
    "                        if constraint in all_class_votes:\n",
    "                            all_class_votes[constraint] += 1\n",
    "                        else:\n",
    "                            all_class_votes[constraint] = 1\n",
    "        \n",
    "        max_votes = []\n",
    "        max_score = 0\n",
    "        for vote in all_class_votes:\n",
    "            if all_class_votes[vote] == max_score:\n",
    "                max_votes.append(vote)\n",
    "            if all_class_votes[vote] > max_score:\n",
    "                max_votes = []\n",
    "                max_votes.append(vote)\n",
    "                max_score = all_class_votes[vote]\n",
    "                \n",
    "        elected = \"\"\n",
    "        max_score = 0\n",
    "        for vote in max_votes:\n",
    "            if vote in instance_counts:\n",
    "                if instance_counts[vote] > max_score:\n",
    "                    elected = vote\n",
    "                    max_score = instance_counts[vote]\n",
    "                \n",
    "        final_guesses[node] = elected\n",
    "    \n",
    "#     values_map = {}\n",
    "#     values = final_guesses.values()\n",
    "#     for value in values:\n",
    "#         if value in values_map:\n",
    "#             values_map[value] += 1\n",
    "#         else:\n",
    "#             values_map[value] = 1\n",
    "#     print(values_map)\n",
    "    \n",
    "    return final_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add instance counts for tiebreaker\n",
    "import csv\n",
    "\n",
    "instance_counts = {}\n",
    "tsv_file = open(f'../statistics.Pinstance_count.tsv/statistics.Pinstance_count.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    instance_counts[line[0]] = int(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded entities and rels\n",
      "loading model\n",
      "loaded model\n",
      "loaded state dict\n",
      "loaded embeddings\n",
      "torch.Size([212010680, 100])\n",
      "tensor([ 72, 167, 196, 188, 212,  93,  94, 191, 159, 240, 128,  61,  17, 222,\n",
      "          8, 190,  57,  44,  98,  61, 237, 146, 204, 189, 225, 160, 170,  62,\n",
      "         85, 136, 135, 190,  15, 233,  60,  61,  87, 130,   1, 190,  99, 186,\n",
      "        251,  61, 177, 243, 204,  60, 187,  24, 205, 190,   2, 215, 113, 190,\n",
      "         97,  37, 128, 190, 144,  44,  37,  62, 249, 145, 120,  62, 178, 155,\n",
      "        156, 190, 183, 200,  15, 190,  96, 202, 190,  60,  44, 130,  31, 190,\n",
      "         59, 101,  78, 190,   0, 122, 173,  61,  62,  69,  27, 190, 102, 166,\n",
      "        146,  61], dtype=torch.uint8)\n",
      "[-0.20318848  0.38883767 -0.13042542  0.40719104  0.0073998   0.02770344\n",
      " -0.3692729  -0.07117436 -0.45070335  0.2896174  -0.11128167  0.1264658\n",
      "  0.08620919 -0.17981598  0.18693425 -0.12659058 -0.5986237  -0.02160399\n",
      "  0.1482508   0.4913708  -0.1796804   0.17583902  0.06972955  0.07167171\n",
      "  0.02379654 -0.22503522  1.0755986   0.00901391 -0.7865988  -0.2122667\n",
      " -0.32557395  0.34689614 -0.22626309 -1.1290427   0.0488675   0.05771735\n",
      " -0.00541829  0.17369756 -0.20103256 -0.0490636   0.07369805 -0.2237563\n",
      " -0.25194123 -0.45781514  0.16527054  0.34035423  0.25603297 -0.5619334\n",
      "  0.41686857  0.25712463 -0.04911556  0.30250528  0.62034875  0.09877616\n",
      "  0.1639844  -0.05870891 -0.15814476 -0.20492348  0.30170998  0.40802798\n",
      " -0.08628733  0.06775033 -0.4245951   0.13935184 -0.2684929   0.03614282\n",
      " -0.17198777  0.25158674 -0.00753019 -0.25713655  0.11366972 -0.01948963\n",
      "  0.34772262  0.7430785  -0.11297054  0.2983229   0.10804557  0.17690133\n",
      "  0.13133216  0.35052758 -0.03693147  0.14169978  0.25800303  0.11400685\n",
      "  0.55569196  0.08804983  0.31959212  0.09830749  0.36676648 -0.03308494\n",
      "  0.05974544  0.2051711   0.5016865   0.13420045  0.23636228 -0.28837684\n",
      "  0.42686364 -0.53240174 -0.0087847  -0.10221966]\n",
      "[-0.48855284 -0.5914004   0.66119033  0.6901398  -0.18685941  0.06233354\n",
      " -0.39165506  0.2333057  -0.61029834  0.58377546  0.18392012  0.3154819\n",
      " -0.49378267 -0.01871726  0.0443705   0.5111822  -0.7542158   0.5285677\n",
      " -0.32453454 -0.4009692   0.5335464   1.2138984   0.6303204   0.55072534\n",
      "  0.757356   -0.2646632   0.73756146 -0.84452343  0.3644982  -0.08229386\n",
      "  0.3436392   0.7729471   0.5444861  -1.7208489   0.35668483 -1.073003\n",
      " -0.28693742  0.00306345 -0.37076482 -0.5420866   0.00920443  0.07782724\n",
      "  0.04143581 -0.9763015   0.24260312 -0.7226388   0.8523348   0.14464964\n",
      "  1.1652092  -0.1007899   0.47361737  0.27246934 -0.5907507   0.5150668\n",
      "  0.04078826  1.0324106   0.27340034 -0.27631372  0.6945929   0.04712105\n",
      " -0.14644982  0.22037911 -0.130953    0.88873863  0.70191854  0.10004565\n",
      " -0.32397005  0.04234171 -0.5561562   0.5682733   0.33865812 -0.5993124\n",
      " -0.30060592 -0.5162239   0.41391557  0.33616215 -0.15146883 -0.75028807\n",
      " -0.36662468  0.6548798   0.3358792  -0.08306112  0.08965431  0.591609\n",
      "  0.94894004 -0.08365047 -0.2899489   0.04784971  0.06815382 -0.10775455\n",
      "  0.24555367 -0.8573544  -0.01032875  1.121497   -0.41464844 -0.7781988\n",
      " -0.09392592  0.21050866 -0.36146706  0.21686177]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gensim.models import KeyedVectors\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py, torch\n",
    "from torchbiggraph.model import ComplexDiagonalDynamicOperator, DotComparator, CosComparator\n",
    "\n",
    "vector_dimension = 100\n",
    "\n",
    "# prepare embeddings data\n",
    "\n",
    "relation_names_list = json.load(open(\"/out/embeddings/dynamic_rel_names.json\"))\n",
    "entity_names_list = json.load(open(\"/out/embeddings/entity_names_all_0.json\"))\n",
    "print(\"loaded entities and rels\")\n",
    "prop_count = len(relation_names_list)\n",
    "\n",
    "# operators\n",
    "operator_lhs = ComplexDiagonalDynamicOperator(vector_dimension, prop_count)\n",
    "operator_rhs = ComplexDiagonalDynamicOperator(vector_dimension, prop_count)\n",
    "comparator = DotComparator()\n",
    "cos_comparator = CosComparator()\n",
    "print(\"loading model\")\n",
    "with h5py.File(\"/out/embeddings/model.v600.h5\", \"r\") as hf:\n",
    "    operator_state_dict_lhs = {\n",
    "        \"real\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/real\"][...]),\n",
    "        \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/imag\"][...]),\n",
    "    }\n",
    "    operator_state_dict_rhs = {\n",
    "        \"real\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/real\"][...]),\n",
    "        \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/imag\"][...]),\n",
    "    }\n",
    "print(\"loaded model\")\n",
    "    \n",
    "operator_lhs.load_state_dict(operator_state_dict_lhs)\n",
    "operator_rhs.load_state_dict(operator_state_dict_rhs)\n",
    "print(\"loaded state dict\")\n",
    "\n",
    "entity_to_index = {}\n",
    "for i, entity in enumerate(entity_names_list):\n",
    "    entity_to_index[entity] = i\n",
    "    \n",
    "\n",
    "rel_index = {}\n",
    "for i, rel in enumerate(relation_names_list):\n",
    "    rel_index[rel] = i\n",
    "    \n",
    "# Load the embeddings\n",
    "#with h5py.File(\"/out/embeddings/embeddings_all_0.v600.h5\", \"r\") as hf:\n",
    "hf = np.memmap(\"/out/embeddings/wikidata-20210215-dwd-v2-similarity-embed.2021-10-03T12_14.complex.np.mmap\", mode='r',\n",
    "              shape=(212010680,100))\n",
    "arnold_embedding = torch.from_numpy(hf)\n",
    "print(\"loaded embeddings\")\n",
    "print(np.shape(arnold_embedding))\n",
    "print(arnold_embedding[0])\n",
    "\n",
    "def get_embed(head, relation=None):\n",
    "    ''' This function generate the embeddings for the tail entities:\n",
    "            Head entities: Obtained from the model\n",
    "            Head + relation: Obtained using torch\n",
    "        :param head: subject Qnode\n",
    "        :param relation: optional property\n",
    "    '''\n",
    "    if relation is None:\n",
    "        return arnold_embedding[entity_to_index[head], :].detach().numpy()\n",
    "    return  operator_lhs(\n",
    "                arnold_embedding[entity_to_index[head], :].view(1, vector_dimension),\n",
    "                torch.tensor([rel_index[relation]])\n",
    "            ).detach().numpy()[0]\n",
    "\n",
    "def kgtk_most_similar(\n",
    "    vectors,\n",
    "    positive,\n",
    "    relation_label=\"similarity_score\",\n",
    "    add_label_description=False,\n",
    "    output_path=None,\n",
    "    topn=25,\n",
    "):\n",
    "    \"\"\"\n",
    "    find topn similar Qnodes, add label and decription for the Qnodes\n",
    "    \n",
    "    :param vectors: vector space loaded into gensim KeyedVectors model\n",
    "    :param positive: vector(s) or Qnode(s) to find similar entities for\n",
    "    :param relation_label: name of the property to be used for the output file\n",
    "    :param add_label_description: boolean parameter to add label and description for matched entities\n",
    "    :param output_path: path to store the output file\n",
    "    :param topn: desirednumber of similar entities\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if add_label_description:\n",
    "        fp = tempfile.NamedTemporaryFile(\n",
    "            mode=\"w\", suffix=\".tsv\", delete=False, encoding=\"utf-8\"\n",
    "        )\n",
    "        fp.write(\"node1\\tlabel\\tnode2\\n\")\n",
    "        for (qnode, similarity) in vectors.most_similar(positive=positive, topn=topn):\n",
    "            fp.write(\"{}\\t{}\\t{}\\n\".format(qnode, relation_label, similarity))\n",
    "        filename = fp.name\n",
    "        fp.close()\n",
    "        \n",
    "        os.environ[\"_temp_file\"] = filename\n",
    "\n",
    "        result = !$kypher -i label -i description -i \"$_temp_file\" --as sim \\\n",
    "--match 'sim: (n1)-[]->(similarity), label: (n1)-[]->(lab), description: (n1)-[]->(des)' \\\n",
    "--return 'distinct n1 as node1, similarity as node2, \"similarity\" as label, lab as `node1;label`, des as `node1;description`' \\\n",
    "--order-by 'cast(similarity, float) desc' \n",
    "        \n",
    "        os.remove(filename)\n",
    "        \n",
    "    else:\n",
    "        result.append(\"node1\\tlabel\\tnode2\\n\")\n",
    "        for (qnode, similarity) in vectors.most_similar(positive=positive, topn=topn):\n",
    "            result.append(\"{}\\t{}\\t{}\\n\".format(qnode, relation_label, similarity))\n",
    "\n",
    "    if output_path:\n",
    "        handle = open(output_path, \"w\")\n",
    "        for line in result:\n",
    "            handle.write(line)\n",
    "            handle.write(\"\\n\")\n",
    "        handle.close()\n",
    "    else:\n",
    "        columns = result[0].split(\"\\t\")\n",
    "        data = []\n",
    "        for line in result[1:]:\n",
    "            data.append(line.split(\"\\t\"))\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "ge_vectors = KeyedVectors.load_word2vec_format(f\"/out/embeddings/embeddings.{property_label}.{orientation}.w2v\", binary=False)\n",
    "print(ge_vectors[0])\n",
    "print(ge_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithEmbeddings(inputs):\n",
    "    final_guesses = {}\n",
    "    for cla in inputs:\n",
    "        _vector = get_embed(cla, 'P31')\n",
    "        final_guesses[cla] = kgtk_most_similar(ge_vectors, positive=[_vector], topn=1)[\"node1\"].array[0]\n",
    "    return final_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
