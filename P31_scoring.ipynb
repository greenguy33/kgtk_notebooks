{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "property_label = \"P19\"\n",
    "# should be \"subjects\" or \"objects\"\n",
    "orientation = \"objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node subject props size:  8.098470363288719\n",
      "distinct node subject props:  99\n",
      "node object props size:  0.654397705544933\n",
      "distinct node object props:  29\n",
      "distinct classes:  2092\n",
      "making predictions...\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "retrieving correct answers...\n",
      "retrieving scores...\n",
      "final avg. score:  0.021639216061185473\n",
      "Q100165600 850 0.0\n",
      "Q101246540 418 0.0\n",
      "Q100162344 186 0.026121505376344088\n",
      "Q3104508 162 0.0\n",
      "Q100740737 155 0.05704129032258064\n",
      "Q101244560 68 0.26021647058823566\n",
      "Q58487031 36 0.0\n",
      "Q100163998 32 0.2969600000000001\n",
      "Q100271152 30 0.0\n",
      "Q100296203 25 0.0\n",
      "Q16735601 19 0.0\n",
      "Q100942530 16 0.021437499999999995\n",
      "Q2003810 14 0.0\n",
      "Q46629343 12 0.11666666666666665\n",
      "Q2113250 9 0.0\n",
      "Q100973182 7 0.2755428571428572\n",
      "Q100754500 6 0.0\n",
      "Q22722 6 0.0\n",
      "Q10271510 5 0.0\n",
      "Q212624 4 0.0\n",
      "Q103888080 3 0.0\n",
      "Q10594592 3 0.0\n",
      "Q100279777 3 0.0\n",
      "Q1000415 3 0.0\n",
      "Q448980 2 0.0\n",
      "Q100029091 2 0.0\n",
      "Q1225491 2 0.0\n",
      "Q2937345 2 0.0\n",
      "Q100158612 2 0.0\n",
      "Q101113283 1 0.7\n",
      "Q10772859 1 0.0\n",
      "Q1001877 1 0.0\n",
      "Q100269445 1 0.0\n",
      "Q10211046 1 0.0\n",
      "Q101067477 1 0.0\n",
      "Q100256453 1 0.0\n",
      "Q99457248 1 0.0\n",
      "Q1001055 1 0.0\n",
      "Q100269589 1 0.0\n",
      "node subject props size:  4.813267813267813\n",
      "distinct node subject props:  73\n",
      "node object props size:  892.5061425061425\n",
      "distinct node object props:  129\n",
      "distinct classes:  1221\n",
      "making predictions...\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "retrieving correct answers...\n",
      "retrieving scores...\n",
      "final avg. score:  0.0034856674856674854\n",
      "Q22722 558 0.0\n",
      "Q100165600 474 0.0\n",
      "Q2003810 61 0.0\n",
      "Q2113250 23 0.0\n",
      "Q100262511 14 0.0\n",
      "Q213159 13 0.0\n",
      "Q100029091 10 0.0\n",
      "Q3104508 10 0.0\n",
      "Q212624 9 0.0\n",
      "Q11689588 8 0.0\n",
      "Q1006719 6 0.0\n",
      "Q10271510 6 0.0\n",
      "Q58487031 5 0.0\n",
      "Q105159301 4 0.36749999999999994\n",
      "Q100251488 3 0.6999999999999998\n",
      "Q100235719 3 0.2286666666666666\n",
      "Q594819 3 0.0\n",
      "Q1007356 2 0.0\n",
      "Q4108101 2 0.0\n",
      "Q1001055 2 0.0\n",
      "Q104097772 1 0.0\n",
      "Q11224256 1 0.0\n",
      "Q10211046 1 0.0\n",
      "Q1225491 1 0.0\n",
      "Q2937345 1 0.0\n",
      "node subject props size:  33.78\n",
      "distinct node subject props:  134\n",
      "node object props size:  2.304\n",
      "distinct node object props:  33\n",
      "distinct classes:  1250\n",
      "making predictions...\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "retrieving correct answers...\n",
      "retrieving scores...\n",
      "final avg. score:  0.010079999999999999\n",
      "Q3104508 961 0.0\n",
      "Q10772859 89 0.0\n",
      "Q2113250 48 0.0\n",
      "Q2003810 36 0.0\n",
      "Q2937345 33 0.0\n",
      "Q212624 24 0.0\n",
      "Q1251417 22 0.5727272727272725\n",
      "Q22722 22 0.0\n",
      "Q100901228 4 0.0\n",
      "Q10271510 4 0.0\n",
      "Q100216147 2 0.0\n",
      "Q16735601 2 0.0\n",
      "Q100707292 1 0.0\n",
      "Q594819 1 0.0\n",
      "Q2257662 1 0.0\n",
      "node subject props size:  40.27936507936508\n",
      "distinct node subject props:  154\n",
      "node object props size:  10436.096825396826\n",
      "distinct node object props:  283\n",
      "distinct classes:  1260\n",
      "making predictions...\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n",
      "predicted 100 classes\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import statistics\n",
    "\n",
    "property_labels = [\"P50\", \"P39\", \"P161\", \"P19\"]\n",
    "orientations = [\"subjects\", \"objects\", \"subjects\", \"objects\"]\n",
    "\n",
    "for index, property_label in enumerate(property_labels):\n",
    "\n",
    "    orientation = orientations[index]\n",
    "\n",
    "    node_subject_props = {}\n",
    "    node_object_props = {}\n",
    "    dis_class = set()\n",
    "    tsv_file = open(f'../output/instance_prediction_datasets/{property_label}.{orientation}.1250.tsv',encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    next(read_tsv)\n",
    "    all_node_subject_props = []\n",
    "    all_node_object_props = []\n",
    "    for line in read_tsv:\n",
    "        dis_class.add(line[0])\n",
    "        if line[5] == \"subject\":\n",
    "            all_node_subject_props.append(line[2])\n",
    "            if line[0] in node_subject_props:\n",
    "                node_subject_props[line[0]].append(line[2])\n",
    "            else:\n",
    "                node_subject_props[line[0]] = [line[2]]\n",
    "        elif line[5] == \"object\":\n",
    "            all_node_object_props.append(line[2])\n",
    "            if line[0] in node_object_props:\n",
    "                node_object_props[line[0]].append(line[2])\n",
    "            else:\n",
    "                node_object_props[line[0]] = [line[2]]\n",
    "\n",
    "    print(\"node subject props size: \", len(all_node_subject_props)/len(dis_class))\n",
    "    print(\"distinct node subject props: \", len(set(all_node_subject_props)))\n",
    "    print(\"node object props size: \", len(all_node_object_props)/len(dis_class))\n",
    "    print(\"distinct node object props: \", len(set(all_node_object_props)))\n",
    "\n",
    "    print(\"distinct classes: \", len(dis_class))\n",
    "\n",
    "    print(\"making predictions...\")\n",
    "    #guesses = predictWithConstraints(dis_class, node_subject_props, node_object_props)\n",
    "    #guesses = predictWithEmbeddings(dis_class)\n",
    "    guesses = predictWithP1963(dis_class, node_subject_props)\n",
    "\n",
    "    print(\"retrieving correct answers...\")\n",
    "    correct_answers = getCorrectAnswers(list(dis_class))\n",
    "\n",
    "    print(\"retrieving scores...\")\n",
    "    scores = []\n",
    "    guess_efficacy = {}\n",
    "\n",
    "    out_file = open(f'../output/p1963/score_report.{property_label}.{orientation}.onlyP1107.tsv', 'w', newline='', encoding=\"utf-8\")\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['Term', 'Term Label', 'Prediction', 'Prediction Label', 'Correct', 'Correct Labels', 'Score'])\n",
    "\n",
    "    for elem in guesses:\n",
    "        this_score = score(guesses[elem], correct_answers[elem])\n",
    "        scores.append(this_score)\n",
    "        if guesses[elem] in guess_efficacy:\n",
    "            guess_efficacy[guesses[elem]][0] += 1\n",
    "            guess_efficacy[guesses[elem]][1] += this_score\n",
    "        else:\n",
    "            guess_efficacy[guesses[elem]] = [1, this_score]\n",
    "            \n",
    "        elem_label = \"\"\n",
    "        guess_label = \"\"\n",
    "        if elem in all_labels:\n",
    "            elem_label = all_labels[elem]\n",
    "        correct =\"|\"\n",
    "        correct_labels = \"|\"\n",
    "        for item in correct_answers[elem]:\n",
    "            correct += item+\"|\"\n",
    "            if item in all_labels:\n",
    "                correct_labels += all_labels[item]+\"|\"\n",
    "            else:\n",
    "                correct_labels += \"|\"\n",
    "        if guesses[elem] in all_labels:\n",
    "            guess_label = all_labels[guesses[elem]]\n",
    "        tsv_writer.writerow([elem, elem_label, guesses[elem], guess_label, correct, correct_labels, this_score])\n",
    "\n",
    "    out_file.close()\n",
    "\n",
    "    print(\"final avg. score: \", statistics.mean(scores))\n",
    "    for k,v in sorted(guess_efficacy.items(), key=lambda p:p[1], reverse=True):\n",
    "        print(k,v[0],(v[1]/v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126326\n"
     ]
    }
   ],
   "source": [
    "# score P31 datasets\n",
    "import csv\n",
    "\n",
    "direct_subclasses = {}\n",
    "direct_superclasses = {}\n",
    "all_superclasses = {}\n",
    "\n",
    "tsv_file = open('../derived.P279.tsv/derived.P279.tsv',encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[1] not in direct_superclasses:\n",
    "        direct_superclasses[line[1]] = [line[3]]\n",
    "    else:\n",
    "        direct_superclasses[line[1]].append(line[3])\n",
    "    if line[3] not in direct_subclasses:\n",
    "        direct_subclasses[line[3]] = [line[1]]\n",
    "    else:\n",
    "        direct_subclasses[line[3]].append(line[1])\n",
    "print(len(direct_subclasses))\n",
    "\n",
    "# tsv_file = open('../derived.P279star.tsv/derived.P279star.tsv',encoding=\"utf-8\")\n",
    "# read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "# next(read_tsv)\n",
    "# for line in read_tsv:\n",
    "#     if line[0] not in all_superclasses:\n",
    "#         all_superclasses[line[0]] = [line[2]]\n",
    "#     else:\n",
    "#         all_superclasses[line[0]].append(line[2])\n",
    "# print(len(all_superclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "\n",
    "def getCorrectAnswers(candidates):\n",
    "    answers = {}\n",
    "#     with open('../derived.P31.tsv/derived.P31.tsv',encoding=\"utf-8\") as f:\n",
    "#         s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "#         while len(candidates) != 0:\n",
    "#             line = s.readline()\n",
    "#             for candidate in candidates:\n",
    "#                 if str.encode(\"\\t\"+candidate+\"\\t\") in line:\n",
    "#                     str1 = line.decode(\"utf-8\")\n",
    "#                     split = str1.split(\"\\t\")\n",
    "#                     answer = split[-1].split(\"\\n\")[0]\n",
    "#                     answers[candidate] = answer\n",
    "#                     candidates.remove(candidate)\n",
    "    tsv_file = open(f'../output/allConstraintsAnalysis_Final/instances/instances.{orientation}.{property_label}.tsv', encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    for line in read_tsv:\n",
    "        if line[0] not in answers:\n",
    "            answers[line[0]] = [line[1]]\n",
    "        else:\n",
    "            answers[line[0]].append(line[1])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (guess, correct):\n",
    "    if guess in correct: \n",
    "        return 1\n",
    "    else:\n",
    "        subclasses = []\n",
    "        superclasses = []\n",
    "        if guess in direct_subclasses:\n",
    "            subclasses = direct_subclasses[guess]\n",
    "        if guess in direct_superclasses:\n",
    "            superclasses = direct_superclasses[guess]\n",
    "        for i in range(1,6):\n",
    "            new_subclasses = []\n",
    "            new_superclasses = []\n",
    "            for subc in subclasses:\n",
    "                if subc in correct:\n",
    "                    if i <= 3:\n",
    "                        return .7**i\n",
    "                    else:\n",
    "                        return .8**i\n",
    "                else:\n",
    "                    if subc in direct_subclasses:\n",
    "                        for new_sub in direct_subclasses[subc]:\n",
    "                            new_subclasses.append(new_sub)\n",
    "            for supc in superclasses:\n",
    "                if supc in correct:\n",
    "                    if i <= 3:\n",
    "                        return .7**i\n",
    "                    else:\n",
    "                        return .8**i\n",
    "                else:\n",
    "                    if supc in direct_superclasses:\n",
    "                        for new_sup in direct_superclasses[supc]:\n",
    "                            new_superclasses.append(new_sup)\n",
    "            subclasses = new_subclasses\n",
    "            superclasses = new_superclasses\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load constraint values\n",
    "typeConstraints = {}\n",
    "tsv_file = open(f'../data/property_constraints/all_type_constraints.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[0].replace(\"http://www.wikidata.org/entity/\",\"\") in typeConstraints:\n",
    "        typeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")].append(line[2].replace(\"http://www.wikidata.org/entity/\",\"\"))\n",
    "    else:\n",
    "        typeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")] = [line[2].replace(\"http://www.wikidata.org/entity/\",\"\")]\n",
    "\n",
    "valueTypeConstraints = {}\n",
    "tsv_file = open(f'../data/property_constraints/all_value_type_constraints.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    if line[0].replace(\"http://www.wikidata.org/entity/\",\"\") in valueTypeConstraints:\n",
    "        valueTypeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")].append(line[2].replace(\"http://www.wikidata.org/entity/\",\"\"))\n",
    "    else:\n",
    "        valueTypeConstraints[line[0].replace(\"http://www.wikidata.org/entity/\",\"\")] = [line[2].replace(\"http://www.wikidata.org/entity/\",\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithConstraints(dis_class, node_subject_props, node_object_props):\n",
    "    final_guesses = {}\n",
    "    for node in dis_class:\n",
    "        all_class_votes = {}\n",
    "        if node in node_subject_props:\n",
    "            subject_props = node_subject_props[node]\n",
    "            for prop in subject_props:\n",
    "                if prop in typeConstraints:\n",
    "                    for constraint in typeConstraints[prop]:\n",
    "                        if constraint in all_class_votes:\n",
    "                            all_class_votes[constraint] += 1\n",
    "                        else:\n",
    "                            all_class_votes[constraint] = 1\n",
    "        if node in node_object_props:\n",
    "            object_props = node_object_props[node]\n",
    "            for prop in object_props:\n",
    "                if prop in valueTypeConstraints:\n",
    "                    for constraint in valueTypeConstraints[prop]:\n",
    "                        if constraint in all_class_votes:\n",
    "                            all_class_votes[constraint] += 1\n",
    "                        else:\n",
    "                            all_class_votes[constraint] = 1\n",
    "        \n",
    "        max_votes = []\n",
    "        max_score = 0\n",
    "        for vote in all_class_votes:\n",
    "            if all_class_votes[vote] == max_score:\n",
    "                max_votes.append(vote)\n",
    "            if all_class_votes[vote] > max_score:\n",
    "                max_votes = []\n",
    "                max_votes.append(vote)\n",
    "                max_score = all_class_votes[vote]\n",
    "                \n",
    "        elected = \"\"\n",
    "        max_score = 0\n",
    "        for vote in max_votes:\n",
    "            if vote in instance_counts:\n",
    "                if instance_counts[vote] > max_score:\n",
    "                    elected = vote\n",
    "                    max_score = instance_counts[vote]\n",
    "                \n",
    "        final_guesses[node] = elected\n",
    "    \n",
    "#     values_map = {}\n",
    "#     values = final_guesses.values()\n",
    "#     for value in values:\n",
    "#         if value in values_map:\n",
    "#             values_map[value] += 1\n",
    "#         else:\n",
    "#             values_map[value] = 1\n",
    "#     print(values_map)\n",
    "    \n",
    "    return final_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add instance counts for tiebreaker\n",
    "import csv\n",
    "\n",
    "instance_counts = {}\n",
    "tsv_file = open(f'../statistics.Pinstance_count.tsv/statistics.Pinstance_count.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    instance_counts[line[0]] = int(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded entities and rels\n",
      "loading model\n",
      "loaded model\n",
      "loaded state dict\n",
      "loaded embeddings\n",
      "torch.Size([212010680, 100])\n",
      "tensor([ 72, 167, 196, 188, 212,  93,  94, 191, 159, 240, 128,  61,  17, 222,\n",
      "          8, 190,  57,  44,  98,  61, 237, 146, 204, 189, 225, 160, 170,  62,\n",
      "         85, 136, 135, 190,  15, 233,  60,  61,  87, 130,   1, 190,  99, 186,\n",
      "        251,  61, 177, 243, 204,  60, 187,  24, 205, 190,   2, 215, 113, 190,\n",
      "         97,  37, 128, 190, 144,  44,  37,  62, 249, 145, 120,  62, 178, 155,\n",
      "        156, 190, 183, 200,  15, 190,  96, 202, 190,  60,  44, 130,  31, 190,\n",
      "         59, 101,  78, 190,   0, 122, 173,  61,  62,  69,  27, 190, 102, 166,\n",
      "        146,  61], dtype=torch.uint8)\n",
      "[-0.20318848  0.38883767 -0.13042542  0.40719104  0.0073998   0.02770344\n",
      " -0.3692729  -0.07117436 -0.45070335  0.2896174  -0.11128167  0.1264658\n",
      "  0.08620919 -0.17981598  0.18693425 -0.12659058 -0.5986237  -0.02160399\n",
      "  0.1482508   0.4913708  -0.1796804   0.17583902  0.06972955  0.07167171\n",
      "  0.02379654 -0.22503522  1.0755986   0.00901391 -0.7865988  -0.2122667\n",
      " -0.32557395  0.34689614 -0.22626309 -1.1290427   0.0488675   0.05771735\n",
      " -0.00541829  0.17369756 -0.20103256 -0.0490636   0.07369805 -0.2237563\n",
      " -0.25194123 -0.45781514  0.16527054  0.34035423  0.25603297 -0.5619334\n",
      "  0.41686857  0.25712463 -0.04911556  0.30250528  0.62034875  0.09877616\n",
      "  0.1639844  -0.05870891 -0.15814476 -0.20492348  0.30170998  0.40802798\n",
      " -0.08628733  0.06775033 -0.4245951   0.13935184 -0.2684929   0.03614282\n",
      " -0.17198777  0.25158674 -0.00753019 -0.25713655  0.11366972 -0.01948963\n",
      "  0.34772262  0.7430785  -0.11297054  0.2983229   0.10804557  0.17690133\n",
      "  0.13133216  0.35052758 -0.03693147  0.14169978  0.25800303  0.11400685\n",
      "  0.55569196  0.08804983  0.31959212  0.09830749  0.36676648 -0.03308494\n",
      "  0.05974544  0.2051711   0.5016865   0.13420045  0.23636228 -0.28837684\n",
      "  0.42686364 -0.53240174 -0.0087847  -0.10221966]\n",
      "[-0.48855284 -0.5914004   0.66119033  0.6901398  -0.18685941  0.06233354\n",
      " -0.39165506  0.2333057  -0.61029834  0.58377546  0.18392012  0.3154819\n",
      " -0.49378267 -0.01871726  0.0443705   0.5111822  -0.7542158   0.5285677\n",
      " -0.32453454 -0.4009692   0.5335464   1.2138984   0.6303204   0.55072534\n",
      "  0.757356   -0.2646632   0.73756146 -0.84452343  0.3644982  -0.08229386\n",
      "  0.3436392   0.7729471   0.5444861  -1.7208489   0.35668483 -1.073003\n",
      " -0.28693742  0.00306345 -0.37076482 -0.5420866   0.00920443  0.07782724\n",
      "  0.04143581 -0.9763015   0.24260312 -0.7226388   0.8523348   0.14464964\n",
      "  1.1652092  -0.1007899   0.47361737  0.27246934 -0.5907507   0.5150668\n",
      "  0.04078826  1.0324106   0.27340034 -0.27631372  0.6945929   0.04712105\n",
      " -0.14644982  0.22037911 -0.130953    0.88873863  0.70191854  0.10004565\n",
      " -0.32397005  0.04234171 -0.5561562   0.5682733   0.33865812 -0.5993124\n",
      " -0.30060592 -0.5162239   0.41391557  0.33616215 -0.15146883 -0.75028807\n",
      " -0.36662468  0.6548798   0.3358792  -0.08306112  0.08965431  0.591609\n",
      "  0.94894004 -0.08365047 -0.2899489   0.04784971  0.06815382 -0.10775455\n",
      "  0.24555367 -0.8573544  -0.01032875  1.121497   -0.41464844 -0.7781988\n",
      " -0.09392592  0.21050866 -0.36146706  0.21686177]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gensim.models import KeyedVectors\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py, torch\n",
    "from torchbiggraph.model import ComplexDiagonalDynamicOperator, DotComparator, CosComparator\n",
    "\n",
    "vector_dimension = 100\n",
    "\n",
    "# prepare embeddings data\n",
    "\n",
    "relation_names_list = json.load(open(\"/out/embeddings/dynamic_rel_names.json\"))\n",
    "entity_names_list = json.load(open(\"/out/embeddings/entity_names_all_0.json\"))\n",
    "print(\"loaded entities and rels\")\n",
    "prop_count = len(relation_names_list)\n",
    "\n",
    "# operators\n",
    "operator_lhs = ComplexDiagonalDynamicOperator(vector_dimension, prop_count)\n",
    "operator_rhs = ComplexDiagonalDynamicOperator(vector_dimension, prop_count)\n",
    "comparator = DotComparator()\n",
    "cos_comparator = CosComparator()\n",
    "print(\"loading model\")\n",
    "with h5py.File(\"/out/embeddings/model.v600.h5\", \"r\") as hf:\n",
    "    operator_state_dict_lhs = {\n",
    "        \"real\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/real\"][...]),\n",
    "        \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/imag\"][...]),\n",
    "    }\n",
    "    operator_state_dict_rhs = {\n",
    "        \"real\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/real\"][...]),\n",
    "        \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/imag\"][...]),\n",
    "    }\n",
    "print(\"loaded model\")\n",
    "    \n",
    "operator_lhs.load_state_dict(operator_state_dict_lhs)\n",
    "operator_rhs.load_state_dict(operator_state_dict_rhs)\n",
    "print(\"loaded state dict\")\n",
    "\n",
    "entity_to_index = {}\n",
    "for i, entity in enumerate(entity_names_list):\n",
    "    entity_to_index[entity] = i\n",
    "    \n",
    "\n",
    "rel_index = {}\n",
    "for i, rel in enumerate(relation_names_list):\n",
    "    rel_index[rel] = i\n",
    "    \n",
    "# Load the embeddings\n",
    "#with h5py.File(\"/out/embeddings/embeddings_all_0.v600.h5\", \"r\") as hf:\n",
    "hf = np.memmap(\"/out/embeddings/wikidata-20210215-dwd-v2-similarity-embed.2021-10-03T12_14.complex.np.mmap\", mode='r',\n",
    "              shape=(212010680,100))\n",
    "arnold_embedding = torch.from_numpy(hf)\n",
    "print(\"loaded embeddings\")\n",
    "print(np.shape(arnold_embedding))\n",
    "print(arnold_embedding[0])\n",
    "\n",
    "def get_embed(head, relation=None):\n",
    "    ''' This function generate the embeddings for the tail entities:\n",
    "            Head entities: Obtained from the model\n",
    "            Head + relation: Obtained using torch\n",
    "        :param head: subject Qnode\n",
    "        :param relation: optional property\n",
    "    '''\n",
    "    if relation is None:\n",
    "        return arnold_embedding[entity_to_index[head], :].detach().numpy()\n",
    "    return  operator_lhs(\n",
    "                arnold_embedding[entity_to_index[head], :].view(1, vector_dimension),\n",
    "                torch.tensor([rel_index[relation]])\n",
    "            ).detach().numpy()[0]\n",
    "\n",
    "def kgtk_most_similar(\n",
    "    vectors,\n",
    "    positive,\n",
    "    relation_label=\"similarity_score\",\n",
    "    add_label_description=False,\n",
    "    output_path=None,\n",
    "    topn=25,\n",
    "):\n",
    "    \"\"\"\n",
    "    find topn similar Qnodes, add label and decription for the Qnodes\n",
    "    \n",
    "    :param vectors: vector space loaded into gensim KeyedVectors model\n",
    "    :param positive: vector(s) or Qnode(s) to find similar entities for\n",
    "    :param relation_label: name of the property to be used for the output file\n",
    "    :param add_label_description: boolean parameter to add label and description for matched entities\n",
    "    :param output_path: path to store the output file\n",
    "    :param topn: desirednumber of similar entities\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if add_label_description:\n",
    "        fp = tempfile.NamedTemporaryFile(\n",
    "            mode=\"w\", suffix=\".tsv\", delete=False, encoding=\"utf-8\"\n",
    "        )\n",
    "        fp.write(\"node1\\tlabel\\tnode2\\n\")\n",
    "        for (qnode, similarity) in vectors.most_similar(positive=positive, topn=topn):\n",
    "            fp.write(\"{}\\t{}\\t{}\\n\".format(qnode, relation_label, similarity))\n",
    "        filename = fp.name\n",
    "        fp.close()\n",
    "        \n",
    "        os.environ[\"_temp_file\"] = filename\n",
    "\n",
    "        result = !$kypher -i label -i description -i \"$_temp_file\" --as sim \\\n",
    "--match 'sim: (n1)-[]->(similarity), label: (n1)-[]->(lab), description: (n1)-[]->(des)' \\\n",
    "--return 'distinct n1 as node1, similarity as node2, \"similarity\" as label, lab as `node1;label`, des as `node1;description`' \\\n",
    "--order-by 'cast(similarity, float) desc' \n",
    "        \n",
    "        os.remove(filename)\n",
    "        \n",
    "    else:\n",
    "        result.append(\"node1\\tlabel\\tnode2\\n\")\n",
    "        for (qnode, similarity) in vectors.most_similar(positive=positive, topn=topn):\n",
    "            result.append(\"{}\\t{}\\t{}\\n\".format(qnode, relation_label, similarity))\n",
    "\n",
    "    if output_path:\n",
    "        handle = open(output_path, \"w\")\n",
    "        for line in result:\n",
    "            handle.write(line)\n",
    "            handle.write(\"\\n\")\n",
    "        handle.close()\n",
    "    else:\n",
    "        columns = result[0].split(\"\\t\")\n",
    "        data = []\n",
    "        for line in result[1:]:\n",
    "            data.append(line.split(\"\\t\"))\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "ge_vectors = KeyedVectors.load_word2vec_format(f\"/out/embeddings/embeddings.{property_label}.{orientation}.w2v\", binary=False)\n",
    "print(ge_vectors[0])\n",
    "print(ge_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithEmbeddings(inputs):\n",
    "    final_guesses = {}\n",
    "    for cla in inputs:\n",
    "        _vector = get_embed(cla, 'P31')\n",
    "        final_guesses[cla] = kgtk_most_similar(ge_vectors, positive=[_vector], topn=1)[\"node1\"].array[0]\n",
    "    return final_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355\n",
      "1354\n",
      "1335\n",
      "1333\n"
     ]
    }
   ],
   "source": [
    "# p1963\n",
    "import csv\n",
    "\n",
    "#tsv_file = open(f'../derived.class.P1963computed.tsv/derived.class.P1963computed.tsv', encoding=\"utf-8\")\n",
    "tsv_file = open(f'../derived.class.P1963computed.count.022422.tsv/derived.class.P1963computed.count.022422.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "count = 0\n",
    "subject_prop_map = {}\n",
    "subject_prop_map_proportion = {}\n",
    "for line in read_tsv:\n",
    "    if line[1] == \"P1114\":\n",
    "        split = line[0].split(\"-\")\n",
    "        thisclass = split[0]\n",
    "        thisprop = split[2]\n",
    "        if thisprop in subject_prop_map:\n",
    "            subject_prop_map[thisprop][thisclass] = line[2]\n",
    "        else:\n",
    "            subject_prop_map[thisprop] = {thisclass:line[2]}\n",
    "    elif line[1] == \"P1107\":\n",
    "        split = line[0].split(\"-\")\n",
    "        thisclass = split[0]\n",
    "        thisprop = split[2]\n",
    "        if thisprop in subject_prop_map_proportion:\n",
    "            subject_prop_map_proportion[thisprop][thisclass] = line[2]\n",
    "        else:\n",
    "            subject_prop_map_proportion[thisprop] = {thisclass:line[2]}\n",
    "print(len(subject_prop_map))\n",
    "print(len(subject_prop_map_proportion))\n",
    "\n",
    "#tsv_file = open(f'../derived.class.P1963computed.inverse.count.tsv/derived.class.P1963computed.inverse.count.tsv', encoding=\"utf-8\")\n",
    "tsv_file = open(f'../derived.class.P1963computed.inverse.count.022422.tsv/derived.class.P1963computed.inverse.count.022422.tsv', encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "count = 0\n",
    "object_prop_map = {}\n",
    "object_prop_map_proportion = {}\n",
    "for line in read_tsv:\n",
    "    if line[1] == \"P1114\":\n",
    "        split = line[0].split(\"-\")\n",
    "        thisclass = split[0]\n",
    "        thisprop = split[2]\n",
    "        if thisprop in object_prop_map:\n",
    "            object_prop_map[thisprop][thisclass] = line[2]\n",
    "        else:\n",
    "            object_prop_map[thisprop] = {thisclass:line[2]}\n",
    "    elif line[1] == \"P1107\":\n",
    "        split = line[0].split(\"-\")\n",
    "        thisclass = split[0]\n",
    "        thisprop = split[2]\n",
    "        if thisprop in object_prop_map_proportion:\n",
    "            object_prop_map_proportion[thisprop][thisclass] = line[2]\n",
    "        else:\n",
    "            object_prop_map_proportion[thisprop] = {thisclass:line[2]}\n",
    "print(len(object_prop_map))\n",
    "print(len(object_prop_map_proportion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import statistics\n",
    "\n",
    "def predictWithP1963(classes, node_subject_props):\n",
    "    guesses = {}\n",
    "    count = 0\n",
    "    for dis_class in classes:\n",
    "        scores = {}\n",
    "        \n",
    "        if dis_class in node_subject_props:\n",
    "            for prop in node_subject_props[dis_class]:\n",
    "                theseclasses = subject_prop_map[prop]\n",
    "                for thisclass in theseclasses:\n",
    "                    if thisclass in subject_prop_map_proportion[prop]:\n",
    "                        # this_score = int(subject_prop_map[prop][thisclass])\n",
    "                        # optionally multiply by proportion\n",
    "                        # this_score = this_score * float(subject_prop_map_proportion[prop][thisclass])\n",
    "                        # go with average of P1107 scores instead\n",
    "                        this_score = float(subject_prop_map_proportion[prop][thisclass])\n",
    "                        if thisclass in scores:\n",
    "                            #scores[thisclass] += this_score\n",
    "                            scores[thisclass].append(this_score)\n",
    "                        else:\n",
    "                            #scores[thisclass] = this_score\n",
    "                            scores[thisclass] = [this_score]\n",
    "                       \n",
    "        if dis_class in node_object_props:\n",
    "            for prop in node_object_props[dis_class]:\n",
    "                theseclasses = object_prop_map[prop]\n",
    "                for thisclass in theseclasses:\n",
    "                    if thisclass in object_prop_map_proportion[prop]:\n",
    "                        # this_score = int(object_prop_map[prop][thisclass])\n",
    "                        # optionally multiply by proportion\n",
    "                        # this_score = this_score * float(object_prop_map_proportion[prop][thisclass])\n",
    "                        # go with average of P1107 scores instead\n",
    "                        this_score = float(object_prop_map_proportion[prop][thisclass])\n",
    "                        if thisclass in scores:\n",
    "                            #scores[thisclass] += this_score\n",
    "                            scores[thisclass].append(this_score)\n",
    "                        else:\n",
    "                            #scores[thisclass] = this_score\n",
    "                            scores[thisclass] = [this_score]\n",
    "\n",
    "# It is for when we use the P1963 star\n",
    "#         counter = Counter(scores)\n",
    "#         counter_res = counter.most_common(100)\n",
    "#         scores = {}\n",
    "#         for k, v in counter_res:\n",
    "#             scores[k] = v\n",
    "#         assert len(scores) == 100     \n",
    "#         # update scores based on specificity in subclass hierarchy\n",
    "#         for guess in scores:\n",
    "#             for guess2 in scores:\n",
    "#                 if guess != guess2 and guess in all_superclasses:\n",
    "#                     if guess2 in all_superclasses[guess]:\n",
    "#                         scores[guess2] = scores[guess2] / 2\n",
    "        max_score = 0\n",
    "        count = count + 1\n",
    "        max_class = \"\"\n",
    "        for guess in scores:\n",
    "            #if scores[guess] > max_score:\n",
    "            if statistics.mean(scores[guess]) > max_score:\n",
    "                #max_score = scores[guess]\n",
    "                max_score = statistics.mean(scores[guess])\n",
    "                max_class = guess\n",
    "        guesses[dis_class] = max_class\n",
    "        if count % 100 == 0:\n",
    "            print(\"predicted 100 classes\")\n",
    "        \n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41845780\n"
     ]
    }
   ],
   "source": [
    "# load labels\n",
    "all_labels = {}\n",
    "tsv_file = open(f'../labels.en.tsv/labels.en.tsv',encoding=\"utf-8\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "next(read_tsv)\n",
    "for line in read_tsv:\n",
    "    all_labels[line[1]] = line[3].replace(\"@en\",\"\")\n",
    "print(len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
